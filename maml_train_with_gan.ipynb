{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cf20f9-4ba4-4c03-a62a-39edf396473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch, os\n",
    "import  numpy as np\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "from    torch.optim import lr_scheduler\n",
    "import  random, sys, pickle\n",
    "from utils.dataloader import train_data_gen , test_data_gen\n",
    "# from maml_meta import Meta\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from    torch import optim\n",
    "from maml_learner import Learner\n",
    "from    torch.nn import functional as F\n",
    "from    copy import deepcopy\n",
    "import json\n",
    "import shutil\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c183b5-bd2c-402f-9e8c-4972c3107350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 60000, 'n_way': 5, 'k_spt': 1, 'k_qry': 15, 'img_sz': 84, 'task_num': 5, 'img_c': 3, 'meta_lr': 0.001, 'update_lr': 0.01, 'update_step': 5, 'update_step_test': 10, 'loss': 'cross_entropy', 'min_learning_rate': 1e-15, 'number_of_training_steps_per_iter': 4, 'multi_step_loss_num_epochs': 15, 'spy_gan_num': 1, 'qry_gan_num': 5, 'num_distractor': 2, 'gan': 1, 'spy_distractor_num': 1, 'qry_distractor_num': 5, 'batch_for_gradient': 25, 'no_save': 0, 'learn_inner_lr': 0, 'create_graph': 0, 'msl': 0, 'single_fast_test': 0, 'consine_schedule': 0, 'save_path': '0704_5way1shot2distractor1gan'}\n"
     ]
    }
   ],
   "source": [
    "with open('maml_configs/0704_5way1shot2distractor1gan.json') as json_file:\n",
    "    args = json.load(json_file)\n",
    "print(args)\n",
    "# if os.path.exists('maml_runs/' + args[\"save_path\"]):\n",
    "#     shutil.rmtree('maml_runs/' + args[\"save_path\"])\n",
    "writer = SummaryWriter('maml_runs/' + args[\"save_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9fa08a-b78c-44f9-8638-cb702894d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "        \n",
    "    if not os.path.exists(\"maml/\" + path):\n",
    "        os.makedirs(\"maml/\" + path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2161c0-84b9-4e23-9d13-e69c08589cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spt_size = args[\"k_spt\"] * args[\"n_way\"]\n",
    "qry_size = args[\"k_qry\"] * args[\"n_way\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d99e4cb-f139-4280-a099-4ebd2a9d2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = 42\n",
    "config = [\n",
    "    ('conv2d', [fm, 3, 3, 3, 1, 0]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    ('bn', [fm]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [fm, fm, 3, 3, 1, 0]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    ('bn', [fm]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [fm, fm, 3, 3, 1, 0]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    ('bn', [fm]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [fm, fm, 3, 3, 1, 0]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    ('bn', [fm]),\n",
    "    ('max_pool2d', [2, 1, 0]),\n",
    "    ('flatten', []),\n",
    "    ('linear', [6, fm * 5 * 5])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cdf48fa-c580-4192-8d5a-a15e0caa9b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load datasets/BelgiumTSC\n",
      "load complete time 0.4288804531097412\n",
      "load datasets/ArTS\n",
      "load complete time 0.398226261138916\n",
      "load datasets/chinese_traffic_sign\n",
      "load complete time 0.7527906894683838\n",
      "load datasets/CVL\n",
      "load complete time 0.5750961303710938\n",
      "load datasets/FullJCNN2013\n",
      "load complete time 0.2891354560852051\n",
      "load datasets/logo_2k\n",
      "load complete time 1.0230731964111328\n",
      "load datasets/GTSRB\n",
      "load complete time 0.09882092475891113\n",
      "load datasets/DFG\n",
      "load complete time 0.035915374755859375\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = train_data_gen(args)\n",
    "test_data_generator = test_data_gen(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4dfa8d-74da-47fe-8b86-ea345eddd113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(train_data_generator, args[\"task_num\"], shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54f53c0d-e7a1-491e-83e9-6e333910049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Conv') != -1:\n",
    "#         nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "#     elif classname.find('BatchNorm') != -1:\n",
    "#         nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "#         nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d3d640-ac6a-4477-85b7-ae20191f9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 3\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "if args[\"gan\"]:\n",
    "    netG = Generator().to(device)\n",
    "    netG.load_state_dict(torch.load(\"GAN_save_models/generator/fixed/model_step_15.pt\")[\"model_state_dict\"])\n",
    "    # netG.apply(weights_init)\n",
    "    # summary(netG,(nz,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6db8cf9-fdb5-403b-a36e-ca89a5c82899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.main = nn.Sequential(\n",
    "#             # input is (nc) x 64 x 64\n",
    "#             nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf) x 32 x 32\n",
    "#             nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 2),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*2) x 16 x 16\n",
    "#             nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 4),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*4) x 8 x 8\n",
    "#             nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 8),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*8) x 4 x 4\n",
    "#             nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "#             nn.Conv2d(1, 1, 2, 1, 0, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         return self.main(input)\n",
    "# netD = Discriminator().to(device)\n",
    "# netD.load_state_dict(torch.load(\"GAN_save_models/discrim/model_step_15.pt\")[\"model_state_dict\"])\n",
    "# # netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b71f113-00a2-4e32-9516-a0c0025e0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize BCELoss function\n",
    "# criterion = nn.BCELoss()\n",
    "# beta1 = 0.5\n",
    "# # Create batch of latent vectors that we will use to visualize\n",
    "# #  the progression of the generator\n",
    "# fixed_noise = torch.randn(50, nz, 1, 1, device=device)\n",
    "\n",
    "# # Establish convention for real and fake labels during training\n",
    "# real_label = 1.\n",
    "# fake_label = 0.\n",
    "\n",
    "# # Setup Adam optimizers for both G and D\n",
    "# optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(beta1, 0.999))\n",
    "# optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e80caf3-d97b-46eb-a1b2-5636ff1315f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training Loop\n",
    "# import cProfile\n",
    "# import pstats\n",
    "# # Lists to keep track of progress\n",
    "# img_list = []\n",
    "# G_losses = []\n",
    "# D_losses = []\n",
    "# iters = 0\n",
    "# num_epochs = 6000\n",
    "# print(\"Starting Training Loop...\")\n",
    "#         # fetch meta_batchsz num of episode each time\n",
    "# step = 0\n",
    "# for epoch in range(args[\"epoch\"]//6000):\n",
    "#     # For each batch in the dataloader\n",
    "#     train_dataloader = DataLoader(train_data_generator, args[\"task_num\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "#     for i, data in enumerate(train_dataloader, 0):\n",
    "#         ############################\n",
    "#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "#         ###########################\n",
    "#         ## Train with all-real batch\n",
    "#         netD.zero_grad()\n",
    "#         # Format batch\n",
    "#         real_cpu = data[0].to(device)\n",
    "#         real_cpu = real_cpu.view(real_cpu.size(0)*real_cpu.size(1),real_cpu.size(2),real_cpu.size(3),real_cpu.size(4))\n",
    "#         b_size = real_cpu.size(0)\n",
    "#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "\n",
    "#         # Forward pass real batch through D\n",
    "#         output = netD(real_cpu).view(-1)\n",
    "#         # Calculate loss on all-real batch\n",
    "\n",
    "#         errD_real = criterion(output, label)\n",
    "#         # Calculate gradients for D in backward pass\n",
    "#         errD_real.backward()\n",
    "#         D_x = output.mean().item()\n",
    "\n",
    "#         ## Train with all-fake batch\n",
    "#         # Generate batch of latent vectors\n",
    "#         noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "#         # Generate fake image batch with G\n",
    "#         fake = netG(noise)\n",
    "#         label.fill_(fake_label)\n",
    "#         # Classify all fake batch with D\n",
    "#         output = netD(fake.detach()).view(-1)\n",
    "#         # Calculate D's loss on the all-fake batch\n",
    "#         errD_fake = criterion(output, label)\n",
    "#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "#         errD_fake.backward()\n",
    "#         D_G_z1 = output.mean().item()\n",
    "#         # Compute error of D as sum over the fake and the real batches\n",
    "#         errD = errD_real + errD_fake\n",
    "#         # Update D\n",
    "#         optimizerD.step()\n",
    "\n",
    "#         ############################\n",
    "#         # (2) Update G network: maximize log(D(G(z)))\n",
    "#         ###########################\n",
    "#         netG.zero_grad()\n",
    "#         label.fill_(real_label)  # fake labels are real for generator cost\n",
    "#         # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "#         output = netD(fake).view(-1)\n",
    "#         # Calculate G's loss based on this output\n",
    "#         errG = criterion(output, label)\n",
    "#         # Calculate gradients for G\n",
    "#         errG.backward()\n",
    "#         D_G_z2 = output.mean().item()\n",
    "#         # Update G\n",
    "#         optimizerG.step()\n",
    "#         # Output training stats\n",
    "#         if i % 100 == 0:\n",
    "#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "#                   % (epoch, args[\"epoch\"]//6000, i, len(train_dataloader),\n",
    "#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "#         # Save Losses for plotting later\n",
    "#         G_losses.append(errG.item())\n",
    "#         D_losses.append(errD.item())\n",
    "\n",
    "#         # Check how the generator is doing by saving G's output on fixed_noise\n",
    "#         if (i % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_dataloader)-1)):\n",
    "#             with torch.no_grad():\n",
    "#                 fake = netG(fixed_noise).detach().cpu()\n",
    "#             img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "#         iters += 1\n",
    "\n",
    "#     torch.save({'model_state_dict': netD.state_dict()}, \"GAN_save_models/discrim/\" + \"model_step_\" + str(epoch) + \".pt\")\n",
    "#     torch.save({'model_state_dict': netG.state_dict()}, \"GAN_save_models/generator/\" + \"model_step_\" + str(epoch) + \".pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e9a5621-204f-4563-92f0-f3550c850868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Meta(nn.Module):\n",
    "    \"\"\"\n",
    "    Meta Learner\n",
    "    \"\"\"\n",
    "    def __init__(self, args, config):\n",
    "        \"\"\"\n",
    "\n",
    "        :param args:\n",
    "        \"\"\"\n",
    "        super(Meta, self).__init__()\n",
    "\n",
    "        self.update_lr = args[\"update_lr\"]\n",
    "        self.meta_lr = args[\"meta_lr\"]\n",
    "        self.n_way = args[\"n_way\"]\n",
    "        self.k_spt = args[\"k_spt\"]\n",
    "        self.k_qry = args[\"k_qry\"]\n",
    "        self.task_num = args[\"task_num\"]\n",
    "        self.update_step = args[\"update_step\"]\n",
    "        self.update_step_test = args[\"update_step_test\"]\n",
    "        self.distractor = args[\"num_distractor\"]\n",
    "        self.net = Learner(config, args[\"img_c\"], args[\"img_sz\"])\n",
    "        self.meta_optim = optim.Adam(self.net.parameters(), lr=self.meta_lr)\n",
    "        self.device = torch.device('cuda')\n",
    "        self.gan = args[\"gan\"]\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry, unlabel_spt_image=None, unlabel_qry_image=None,gan_spt=None, gan_qry=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x_spt:   [b, setsz, c_, h, w]\n",
    "        :param y_spt:   [b, setsz]\n",
    "        :param x_qry:   [b, querysz, c_, h, w]\n",
    "        :param y_qry:   [b, querysz]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        task_num, setsz, c_, h, w = x_spt.size()\n",
    "        querysz = x_qry.size(1)\n",
    "        if self.gan :\n",
    "            gan_sptsz = gan_spt.size(1)\n",
    "            gan_qrysz = gan_qry.size(1)\n",
    "        \n",
    "        else:\n",
    "            gan_qrysz = 0\n",
    "        if self.distractor or gan_sptsz:\n",
    "            corrects = {}\n",
    "            corrects[\"total_query_nway\"] = np.zeros(self.update_step + 1)\n",
    "            if self.distractor:\n",
    "                unlabel_querysz = unlabel_qry.size(1)\n",
    "                corrects[\"query_nway\"] = np.zeros(self.update_step + 1)\n",
    "                corrects[\"label_query_nway\"] = np.zeros(self.update_step + 1)\n",
    "                corrects[\"unlabel_query_nway\"] = np.zeros(self.update_step + 1)\n",
    "            if self.gan :\n",
    "                corrects[\"gan_query_nway\"] = np.zeros(self.update_step + 1)\n",
    "        else:\n",
    "            corrects = {key: np.zeros(self.update_step + 1) for key in \n",
    "                [\n",
    "                \"query_nway\"\n",
    "                ]}\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]  # losses_q[i] is the loss on step i\n",
    "\n",
    "        for i in range(task_num):\n",
    "            spt_image = x_spt[i]\n",
    "            spt_label = y_spt[i]\n",
    "            qry_image = x_qry[i]\n",
    "            qry_label = y_qry[i]\n",
    "            if self.distractor:\n",
    "                spt_image = torch.concat((spt_image,unlabel_spt[i]))\n",
    "                spt_unlabel_label = torch.full((unlabel_spt.size(1),), 5, dtype=torch.long,device=self.device)\n",
    "                spt_label = torch.cat((spt_label,spt_unlabel_label))\n",
    "                qry_image = torch.concat((qry_image,unlabel_qry[i]))\n",
    "                qry_unlabel_label = torch.full((unlabel_qry.size(1),), 5, dtype=torch.long,device=self.device)\n",
    "                qry_label = torch.cat((qry_label,qry_unlabel_label))\n",
    "            if self.gan :\n",
    "                spt_image = torch.concat((spt_image,gan_spt[i]))\n",
    "                spt_gan_label = torch.full((gan_spt.size(1),), 5, dtype=torch.long,device=self.device)\n",
    "                spt_label = torch.cat((spt_label,spt_gan_label))\n",
    "                qry_image = torch.concat((qry_image,gan_qry[i]))\n",
    "                qry_gan_label = torch.full((gan_qry.size(1),), 5, dtype=torch.long,device=self.device)\n",
    "                qry_label = torch.cat((qry_label,qry_gan_label))\n",
    "\n",
    "            # 1. run the i-th task and compute loss for k=0\n",
    "            logits = self.net(spt_image, vars=None, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, spt_label)\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, self.net.parameters())))\n",
    "\n",
    "            # this is the loss and accuracy before first update\n",
    "            with torch.no_grad():\n",
    "                # [setsz, nway]\n",
    "                if self.distractor or gan_sptsz:\n",
    "                    total_logits_q = self.net(qry_image, self.net.parameters(), bn_training=False)\n",
    "                    total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                    total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                    corrects['total_query_nway'][0] += total_q_correct\n",
    "                    loss_q = F.cross_entropy(total_logits_q, qry_label)\n",
    "                    losses_q[0] += loss_q\n",
    "                    if self.distractor:\n",
    "                        label_logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=False)\n",
    "                        label_pred_q = F.softmax(label_logits_q, dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                        corrects['label_query_nway'][0] += label_pred_q_correct\n",
    "                        label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                        corrects['query_nway'][0] += label_pred_q_correct\n",
    "                        \n",
    "\n",
    "                        unlabel_logits_q = self.net(unlabel_qry[i], self.net.parameters(), bn_training=False)\n",
    "                        unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                        other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                        corrects[\"unlabel_query_nway\"][0] += other\n",
    "                    if self.gan :\n",
    "                        gan_logits_q = self.net(gan_qry[i], self.net.parameters(), bn_training=False)\n",
    "                        gan_pred_q = F.softmax(gan_logits_q, dim=1).argmax(dim=1)\n",
    "                        gan_counts = torch.eq(gan_pred_q, qry_gan_label).sum().item()\n",
    "                        corrects[\"gan_query_nway\"][0] += gan_counts\n",
    "                else:\n",
    "                    logits_q = self.net(qry_image, self.net.parameters(), bn_training=True)\n",
    "                    loss_q = F.cross_entropy(logits_q, qry_label)\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                    corrects['query_nway'][0] += q_discrim_correct\n",
    "                    losses_q[0] += loss_q\n",
    "            # this is the loss and accuracy after the first update\n",
    "            with torch.no_grad():\n",
    "                # [setsz, nway]\n",
    "                if self.distractor or gan_sptsz:\n",
    "                    \n",
    "                    total_logits_q = self.net(qry_image,fast_weights , bn_training=False)\n",
    "                    total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                    total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                    corrects['total_query_nway'][1] += total_q_correct\n",
    "                    loss_q = F.cross_entropy(total_logits_q, qry_label)\n",
    "                    losses_q[1] += loss_q\n",
    "                    if self.distractor:\n",
    "                        label_logits_q = self.net(x_qry[i], fast_weights, bn_training=False)\n",
    "                        label_pred_q = F.softmax(label_logits_q, dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                        corrects['label_query_nway'][1] += label_pred_q_correct\n",
    "                        label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                        corrects['query_nway'][1] += label_pred_q_correct\n",
    "                        \n",
    "                        unlabel_logits_q = self.net(unlabel_qry[i], fast_weights, bn_training=False)\n",
    "                        unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                        other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                        corrects[\"unlabel_query_nway\"][1] += other\n",
    "                    if self.gan :\n",
    "                        gan_logits_q = self.net(gan_qry[i], fast_weights, bn_training=False)\n",
    "                        gan_pred_q = F.softmax(gan_logits_q, dim=1).argmax(dim=1)\n",
    "                        gan_counts = torch.eq(gan_pred_q, qry_gan_label).sum().item()\n",
    "                        corrects[\"gan_query_nway\"][1] += gan_counts\n",
    "                else:\n",
    "                    logits_q = self.net(qry_image, fast_weights, bn_training=False)\n",
    "                    loss_q = F.cross_entropy(logits_q, qry_label)\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                    corrects['query_nway'][1] += q_discrim_correct\n",
    "                    losses_q[1] += loss_q\n",
    "            for k in range(1, self.update_step):\n",
    "                # 1. run the i-th task and compute loss for k=1~K-1\n",
    "                logits = self.net(spt_image, fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(logits, spt_label)\n",
    "                # 2. compute grad on theta_pi\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                # 3. theta_pi = theta_pi - train_lr * grad\n",
    "                fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n",
    "\n",
    "                logits_q = self.net(qry_image, fast_weights, bn_training=True)\n",
    "                # loss_q will be overwritten and just keep the loss_q on last update step.\n",
    "                loss_q = F.cross_entropy(logits_q, qry_label)\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if self.distractor or gan_sptsz:\n",
    "                        total_logits_q = self.net(qry_image, fast_weights, bn_training=False)\n",
    "                        total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                        total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                        corrects['total_query_nway'][k+1] += total_q_correct\n",
    "                        if self.distractor:\n",
    "                            label_logits_q = self.net(x_qry[i], fast_weights, bn_training=False)\n",
    "                            label_pred_q = F.softmax(label_logits_q, dim=1).argmax(dim=1)\n",
    "                            label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                            corrects['label_query_nway'][k+1] += label_pred_q_correct\n",
    "                            label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                            label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                            corrects['query_nway'][k+1] += label_pred_q_correct\n",
    "                            \n",
    "                            unlabel_logits_q = self.net(unlabel_qry[i], fast_weights, bn_training=False)\n",
    "                            unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                            other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                            corrects[\"unlabel_query_nway\"][k+1] += other\n",
    "                        if self.gan :\n",
    "                            gan_logits_q = self.net(gan_qry[i], fast_weights, bn_training=False)\n",
    "                            gan_pred_q = F.softmax(gan_logits_q, dim=1).argmax(dim=1)\n",
    "                            gan_counts = torch.eq(gan_pred_q, qry_gan_label).sum().item()\n",
    "                            corrects[\"gan_query_nway\"][k+1] += gan_counts\n",
    "                    else:\n",
    "                        pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                        q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                        corrects['query_nway'][k+1] += q_discrim_correct\n",
    "\n",
    "        # end of all tasks\n",
    "        # sum over all losses on query set across all tasks\n",
    "        loss_q = losses_q[-1] / task_num\n",
    "        # optimize theta parameters\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.backward()\n",
    "\n",
    "        self.meta_optim.step()\n",
    "        \n",
    "        accs = {}\n",
    "        if (self.distractor or self.gan):\n",
    "            accs[\"total_query_nway\"] = corrects[\"total_query_nway\"] / (task_num * (querysz + unlabel_querysz + gan_qrysz))\n",
    "            if self.distractor:\n",
    "                accs[\"label_query_nway\"] = corrects[\"label_query_nway\"] / (task_num * querysz)\n",
    "                accs[\"query_nway\"] = corrects[\"query_nway\"] / (task_num * querysz)\n",
    "                accs[\"unlabel_query_nway\"] = corrects[\"unlabel_query_nway\"] / (task_num * unlabel_querysz)\n",
    "            if gan_qrysz:\n",
    "                accs['gan_query_nway'] = corrects[\"gan_query_nway\"] / (task_num * gan_qrysz)\n",
    "        else:\n",
    "            accs[\"query_nway\"] = corrects[\"query_nway\"] / (task_num * querysz)\n",
    "        return accs,loss_q\n",
    "\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry, unlabel_spt=None, unlabel_qry=None, gan_spt=None, gan_qry=None):\n",
    "\n",
    "        assert len(x_spt.shape) == 4\n",
    "        querysz = x_qry.size(0)\n",
    "        if self.gan :\n",
    "            gan_sptsz = gan_spt.size(0)\n",
    "            gan_qrysz = gan_qry.size(0)\n",
    "        else:\n",
    "            gan_sptsz = gan_qrysz = 0\n",
    "        if self.distractor or self.gan:\n",
    "            corrects = {}\n",
    "            corrects[\"total_query_nway\"] = np.zeros(self.update_step_test + 1)\n",
    "            if self.distractor:\n",
    "                unlabel_querysz = unlabel_qry.size(0)\n",
    "                corrects[\"label_query_nway\"] = np.zeros(self.update_step_test + 1)\n",
    "                corrects[\"query_nway\"] = np.zeros(self.update_step_test + 1)\n",
    "                corrects[\"unlabel_query_nway\"] = np.zeros(self.update_step_test + 1)\n",
    "            if self.gan:\n",
    "                corrects[\"gan_query_nway\"] = np.zeros(self.update_step_test + 1)\n",
    "        else:\n",
    "            corrects = {key: np.zeros(self.update_step_test + 1) for key in \n",
    "                            [\n",
    "                            \"query_nway\"\n",
    "                            ]}\n",
    "        # in order to not ruin the state of running_mean/variance and bn_weight/bias\n",
    "        # we finetunning on the copied model instead of self.net\n",
    "        net = deepcopy(self.net)\n",
    "        spt_image = x_spt\n",
    "        spt_label = y_spt\n",
    "        qry_image = x_qry\n",
    "        qry_label = y_qry\n",
    "        if self.distractor:\n",
    "            spt_image = torch.concat((spt_image,unlabel_spt))\n",
    "            spt_unlabel_label = torch.full((unlabel_spt.size(0),), 5, dtype=torch.long,device=self.device)\n",
    "            spt_label = torch.cat((spt_label,spt_unlabel_label))\n",
    "            qry_image = torch.concat((qry_image,unlabel_qry))\n",
    "            qry_unlabel_label = torch.full((unlabel_qry.size(0),), 5, dtype=torch.long,device=self.device)\n",
    "            qry_label = torch.cat((qry_label,qry_unlabel_label))\n",
    "        if self.gan :\n",
    "            spt_image = torch.concat((spt_image,gan_spt))\n",
    "            spt_gan_label = torch.full((gan_spt.size(0),), 5, dtype=torch.long,device=self.device)\n",
    "            spt_label = torch.cat((spt_label,spt_gan_label))\n",
    "            qry_image = torch.concat((qry_image,gan_qry))\n",
    "            qry_gan_label = torch.full((gan_qry.size(0),), 5, dtype=torch.long,device=self.device)\n",
    "            qry_label = torch.cat((qry_label,qry_gan_label))\n",
    "        \n",
    "        # 1. run the i-th task and compute loss for k=0\n",
    "        logits = net(spt_image)\n",
    "        loss = F.cross_entropy(logits, spt_label)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters())))\n",
    "\n",
    "        # this is the loss and accuracy before first update\n",
    "        with torch.no_grad():\n",
    "            if self.distractor or gan_sptsz:\n",
    "                total_logits_q = self.net(qry_image, self.net.parameters(), bn_training=False)\n",
    "                total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                corrects['total_query_nway'][0] += total_q_correct\n",
    "                loss_q = F.cross_entropy(total_logits_q, qry_label)\n",
    "                if self.distractor:\n",
    "                    label_logits_q = self.net(x_qry, self.net.parameters(), bn_training=False)\n",
    "                    label_pred_q = F.softmax(label_logits_q, dim=1).argmax(dim=1)\n",
    "                    label_pred_q_correct = torch.eq(label_pred_q, y_qry).sum().item()\n",
    "                    corrects['label_query_nway'][0] += label_pred_q_correct\n",
    "                    \n",
    "                    label_logits_q = self.net(x_qry, self.net.parameters(), bn_training=False)\n",
    "                    label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                    label_pred_q_correct = torch.eq(label_pred_q, y_qry).sum().item()\n",
    "                    corrects['query_nway'][0] += label_pred_q_correct\n",
    "                    \n",
    "                    unlabel_logits_q = self.net(unlabel_qry, self.net.parameters(), bn_training=False)\n",
    "                    unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                    other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                    corrects[\"unlabel_query_nway\"][0] += other\n",
    "                if self.gan :\n",
    "                    gan_logits_q = self.net(gan_qry, self.net.parameters(), bn_training=False)\n",
    "                    gan_pred_q = F.softmax(gan_logits_q, dim=1).argmax(dim=1)\n",
    "                    gan_counts = torch.eq(gan_pred_q, qry_gan_label).sum().item()\n",
    "                    corrects[\"gan_query_nway\"][0] += gan_counts\n",
    "            else:\n",
    "                logits_q = self.net(qry_image, self.net.parameters(), bn_training=True)\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                corrects['query_nway'][0] += q_discrim_correct\n",
    "        # this is the loss and accuracy after the first update\n",
    "        with torch.no_grad():\n",
    "            if self.distractor or gan_sptsz:\n",
    "\n",
    "                total_logits_q = self.net(qry_image,fast_weights , bn_training=False)\n",
    "                total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                corrects['total_query_nway'][1] += total_q_correct\n",
    "                loss_q = F.cross_entropy(total_logits_q, qry_label)\n",
    "                if self.distractor:\n",
    "                    label_logits_q = self.net(x_qry, fast_weights, bn_training=False)\n",
    "                    label_pred_q = F.softmax(label_logits_q, dim=1).argmax(dim=1)\n",
    "                    label_pred_q_correct = torch.eq(label_pred_q, y_qry).sum().item()\n",
    "                    corrects['label_query_nway'][1] += label_pred_q_correct\n",
    "                    \n",
    "                    label_logits_q = self.net(x_qry, fast_weights, bn_training=False)\n",
    "                    label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                    label_pred_q_correct = torch.eq(label_pred_q, y_qry).sum().item()\n",
    "                    corrects['query_nway'][1] += label_pred_q_correct\n",
    "                    \n",
    "                    unlabel_logits_q = self.net(unlabel_qry, fast_weights, bn_training=False)\n",
    "                    unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                    other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                    corrects[\"unlabel_query_nway\"][1] += other\n",
    "                if self.gan :\n",
    "                    gan_logits_q = self.net(gan_qry, fast_weights, bn_training=False)\n",
    "                    gan_pred_q = F.softmax(gan_logits_q, dim=1).argmax(dim=1)\n",
    "                    gan_counts = torch.eq(gan_pred_q, qry_gan_label).sum().item()\n",
    "                    corrects[\"gan_query_nway\"][1] += gan_counts\n",
    "            else:\n",
    "                logits_q = self.net(qry_image, fast_weights, bn_training=True)\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                corrects['query_nway'][1] += q_discrim_correct\n",
    "        for k in range(1, self.update_step_test):\n",
    "            # 1. run the i-th task and compute loss for k=1~K-1\n",
    "            logits = net(spt_image, fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, spt_label)\n",
    "            # 2. compute grad on theta_pi\n",
    "            grad = torch.autograd.grad(loss, fast_weights)\n",
    "            # 3. theta_pi = theta_pi - train_lr * grad\n",
    "            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n",
    "\n",
    "            logits_q = net(qry_image, fast_weights, bn_training=True)\n",
    "            # loss_q will be overwritten and just keep the loss_q on last update step.\n",
    "            loss_q = F.cross_entropy(logits_q, qry_label)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if self.distractor or gan_sptsz:\n",
    "                    total_logits_q = self.net(qry_image, fast_weights, bn_training=False)\n",
    "                    total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                    total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                    corrects['total_query_nway'][k+1] += total_q_correct\n",
    "                    if self.distractor:\n",
    "                        label_logits_q = self.net(x_qry, fast_weights, bn_training=False)\n",
    "                        label_pred_q = F.softmax(label_logits_q, dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry).sum().item()\n",
    "                        corrects['label_query_nway'][k+1] += label_pred_q_correct\n",
    "                        \n",
    "                        label_logits_q = self.net(x_qry, fast_weights, bn_training=False)\n",
    "                        label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry).sum().item()\n",
    "                        corrects['query_nway'][k+1] += label_pred_q_correct\n",
    "\n",
    "                        unlabel_logits_q = self.net(unlabel_qry, fast_weights, bn_training=False)\n",
    "                        unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                        other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                        corrects[\"unlabel_query_nway\"][k+1] += other\n",
    "                    if self.gan :\n",
    "                        gan_logits_q = self.net(gan_qry, fast_weights, bn_training=False)\n",
    "                        gan_pred_q = F.softmax(gan_logits_q, dim=1).argmax(dim=1)\n",
    "                        gan_counts = torch.eq(gan_pred_q, qry_gan_label).sum().item()\n",
    "                        corrects[\"gan_query_nway\"][k+1] += gan_counts\n",
    "                else:\n",
    "                    logits_q = self.net(qry_image, fast_weights, bn_training=True)\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                    corrects['query_nway'][k+1] += q_discrim_correct\n",
    "        del net\n",
    "        accs = {}\n",
    "        if (self.distractor or self.gan):\n",
    "            accs[\"total_query_nway\"] = corrects[\"total_query_nway\"] / (querysz + unlabel_querysz + gan_qrysz)\n",
    "            if self.distractor:\n",
    "                accs[\"label_query_nway\"] = corrects[\"label_query_nway\"] / querysz\n",
    "                accs[\"query_nway\"] = corrects[\"query_nway\"] / querysz\n",
    "                accs[\"unlabel_query_nway\"] = corrects[\"unlabel_query_nway\"] / (unlabel_querysz)\n",
    "            if self.gan:\n",
    "                accs['gan_query_nway'] = corrects[\"gan_query_nway\"] / (gan_qrysz)\n",
    "        else:\n",
    "            accs[\"query_nway\"] = corrects[\"query_nway\"] / querysz\n",
    "        return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deb2d02e-c650-4a07-b2ce-5ab10edf5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "maml = Meta(args, config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecadcd4d-b5a1-4e2d-9648-e716f71db135",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "num = sum(map(lambda x: np.prod(x.shape), tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38236a4e-eb80-4c04-9cd8-21792e4f05b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: {'total_query_nway': array([0.15555556, 0.23777778, 0.28888889, 0.3       , 0.28888889,\n",
      "       0.29111111]), 'label_query_nway': array([0.152     , 0.18933333, 0.26933333, 0.27466667, 0.256     ,\n",
      "       0.25866667]), 'query_nway': array([0.20533333, 0.26933333, 0.312     , 0.328     , 0.32      ,\n",
      "       0.336     ]), 'unlabel_query_nway': array([0.2 , 0.48, 0.34, 0.42, 0.44, 0.44]), 'gan_query_nway': array([0.12, 0.48, 0.48, 0.44, 0.48, 0.48])}\n",
      "0 Test acc: {'total_query_nway': array([0.1505, 0.2932, 0.3188, 0.327 , 0.3313, 0.337 , 0.3398, 0.3406,\n",
      "       0.3416, 0.3435, 0.3445], dtype=float16), 'label_query_nway': array([0.1482, 0.26  , 0.2913, 0.2988, 0.3032, 0.3096, 0.312 , 0.3125,\n",
      "       0.3137, 0.3162, 0.317 ], dtype=float16), 'query_nway': array([0.1888, 0.3464, 0.3843, 0.394 , 0.4001, 0.4062, 0.409 , 0.4102,\n",
      "       0.411 , 0.4143, 0.4153], dtype=float16), 'unlabel_query_nway': array([0.2013, 0.5073, 0.5186, 0.535 , 0.5425, 0.545 , 0.5537, 0.5576,\n",
      "       0.56  , 0.56  , 0.565 ], dtype=float16), 'gan_query_nway': array([0.085 , 0.365 , 0.3325, 0.3325, 0.33  , 0.33  , 0.33  , 0.33  ,\n",
      "       0.3225, 0.32  , 0.32  ], dtype=float16)}\n",
      "step: 30 \ttraining acc: {'total_query_nway': array([0.12888889, 0.33333333, 0.38      , 0.39333333, 0.39555556,\n",
      "       0.41111111]), 'label_query_nway': array([0.15466667, 0.376     , 0.38933333, 0.4       , 0.4       ,\n",
      "       0.41866667]), 'query_nway': array([0.15466667, 0.37866667, 0.41066667, 0.42666667, 0.43733333,\n",
      "       0.45866667]), 'unlabel_query_nway': array([0.  , 0.14, 0.38, 0.42, 0.44, 0.44]), 'gan_query_nway': array([0.  , 0.08, 0.24, 0.24, 0.24, 0.24])}\n",
      "step: 60 \ttraining acc: {'total_query_nway': array([0.20888889, 0.35111111, 0.38222222, 0.41555556, 0.41555556,\n",
      "       0.42444444]), 'label_query_nway': array([0.24266667, 0.41066667, 0.424     , 0.43733333, 0.43733333,\n",
      "       0.44266667]), 'query_nway': array([0.24266667, 0.41333333, 0.44266667, 0.456     , 0.464     ,\n",
      "       0.464     ]), 'unlabel_query_nway': array([0.06, 0.06, 0.2 , 0.38, 0.38, 0.38]), 'gan_query_nway': array([0.  , 0.04, 0.12, 0.16, 0.16, 0.24])}\n",
      "step: 90 \ttraining acc: {'total_query_nway': array([0.11777778, 0.40222222, 0.47333333, 0.47777778, 0.48888889,\n",
      "       0.52      ]), 'label_query_nway': array([0.11466667, 0.46666667, 0.528     , 0.52      , 0.51733333,\n",
      "       0.53333333]), 'query_nway': array([0.12533333, 0.46933333, 0.54666667, 0.552     , 0.55466667,\n",
      "       0.57866667]), 'unlabel_query_nway': array([0.1 , 0.06, 0.22, 0.3 , 0.38, 0.5 ]), 'gan_query_nway': array([0.2 , 0.12, 0.16, 0.2 , 0.28, 0.36])}\n",
      "100 Test acc: {'total_query_nway': array([0.1677, 0.36  , 0.42  , 0.4485, 0.4602, 0.467 , 0.4753, 0.4802,\n",
      "       0.4841, 0.4868, 0.49  ], dtype=float16), 'label_query_nway': array([0.1974, 0.4207, 0.4673, 0.4897, 0.4985, 0.503 , 0.5093, 0.5127,\n",
      "       0.5156, 0.5176, 0.52  ], dtype=float16), 'query_nway': array([0.1976, 0.422 , 0.4788, 0.5093, 0.5244, 0.5337, 0.5425, 0.548 ,\n",
      "       0.553 , 0.557 , 0.5605], dtype=float16), 'unlabel_query_nway': array([0.01125, 0.03375, 0.17   , 0.2476 , 0.2812 , 0.3025 , 0.3225 ,\n",
      "       0.3389 , 0.3525 , 0.3638 , 0.3713 ], dtype=float16), 'gan_query_nway': array([0.0375, 0.1025, 0.21  , 0.2325, 0.2426, 0.2576, 0.2676, 0.275 ,\n",
      "       0.2725, 0.2725, 0.275 ], dtype=float16)}\n",
      "step: 120 \ttraining acc: {'total_query_nway': array([0.15111111, 0.29777778, 0.37777778, 0.39111111, 0.42666667,\n",
      "       0.44      ]), 'label_query_nway': array([0.176, 0.312, 0.392, 0.384, 0.416, 0.424]), 'query_nway': array([0.17866667, 0.336     , 0.416     , 0.43733333, 0.48      ,\n",
      "       0.49866667]), 'unlabel_query_nway': array([0.  , 0.24, 0.34, 0.46, 0.52, 0.54]), 'gan_query_nway': array([0.08, 0.2 , 0.24, 0.36, 0.4 , 0.48])}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry \u001b[38;5;241m=\u001b[39m x_spt\u001b[38;5;241m.\u001b[39mto(device), y_spt\u001b[38;5;241m.\u001b[39mto(device), x_qry\u001b[38;5;241m.\u001b[39mto(device), y_qry\u001b[38;5;241m.\u001b[39mto(device), \\\n\u001b[1;32m     26\u001b[0m unlabel_spt\u001b[38;5;241m.\u001b[39mto(device), unlabel_qry\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspy_gan_num\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 28\u001b[0m     accs,loss_q \u001b[38;5;241m=\u001b[39m \u001b[43mmaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_spt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_spt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_qry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_qry\u001b[49m\u001b[43m,\u001b[49m\u001b[43munlabel_spt_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlabel_spt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlabel_qry_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlabel_qry\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgan_spt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgan_spt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_qry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgan_qry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     accs,loss_q \u001b[38;5;241m=\u001b[39m maml(x_spt, y_spt, x_qry, y_qry,unlabel_spt_image\u001b[38;5;241m=\u001b[39munlabel_spt, unlabel_qry_image\u001b[38;5;241m=\u001b[39munlabel_qry)\n",
      "File \u001b[0;32m~/miniconda3/envs/metagan/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mMeta.forward\u001b[0;34m(self, x_spt, y_spt, x_qry, y_qry, unlabel_spt_image, unlabel_qry_image, gan_spt, gan_qry)\u001b[0m\n\u001b[1;32m     96\u001b[0m label_logits_q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(x_qry[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mparameters(), bn_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     97\u001b[0m label_pred_q \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(label_logits_q, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m label_pred_q_correct \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_pred_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_qry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m corrects[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_query_nway\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m label_pred_q_correct\n\u001b[1;32m    100\u001b[0m label_pred_q \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(label_logits_q[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = args[\"save_path\"]\n",
    "step = 0\n",
    "mkdir_p(path)\n",
    "for epoch in range(args[\"epoch\"]//6000):\n",
    "        # fetch meta_batchsz num of episode each time\n",
    "\n",
    "    train_dataloader = DataLoader(train_data_generator, args[\"task_num\"], shuffle=True, num_workers=1, pin_memory=True)\n",
    "    x_spt = y_spt = x_qry = y_qry = unlabel_spt = unlabel_qry = gan_qry = gan_spt = 0\n",
    "    for idx,data  in enumerate(train_dataloader):\n",
    "        if args[\"gan\"]:\n",
    "            with torch.no_grad():\n",
    "                gan_spt_noise = torch.randn(args[\"task_num\"]*args[\"spy_gan_num\"], 100, 1, 1, device=device)\n",
    "                gan_spt = netG(gan_spt_noise).to(device).view(args[\"task_num\"],args[\"spy_gan_num\"],args[\"img_c\"],args[\"img_sz\"],args[\"img_sz\"])\n",
    "                gan_qry_noise = torch.randn(args[\"task_num\"]*args[\"qry_gan_num\"], 100, 1, 1, device=device)\n",
    "                gan_qry = netG(gan_qry_noise).to(device).view(args[\"task_num\"],args[\"qry_gan_num\"],args[\"img_c\"],args[\"img_sz\"],args[\"img_sz\"])\n",
    "        if len(data) == 4:\n",
    "            (x_spt, y_spt, x_qry, y_qry) = data\n",
    "            x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "            if args[\"gan\"]:\n",
    "                accs,loss_q = maml(x_spt, y_spt, x_qry, y_qry,gan_spt=gan_spt, gan_qry=gan_qry)\n",
    "            else:\n",
    "                accs,loss_q = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "        else:\n",
    "            (x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry) = data\n",
    "            x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device), \\\n",
    "            unlabel_spt.to(device), unlabel_qry.to(device)\n",
    "            if args[\"spy_gan_num\"]:\n",
    "                accs,loss_q = maml(x_spt, y_spt, x_qry, y_qry,unlabel_spt_image=unlabel_spt, unlabel_qry_image=unlabel_qry,gan_spt=gan_spt, gan_qry=gan_qry)\n",
    "            else:\n",
    "                accs,loss_q = maml(x_spt, y_spt, x_qry, y_qry,unlabel_spt_image=unlabel_spt, unlabel_qry_image=unlabel_qry)\n",
    "\n",
    "        writer.add_scalar('Loss/train_loss', loss_q, step)\n",
    "        if \"total_query_nway\" in accs:\n",
    "            writer.add_scalar('Accuracy/train_total_query_nway_accuracy', accs[\"total_query_nway\"][-1], step)\n",
    "        if \"label_query_nway\" in accs:\n",
    "            writer.add_scalar('Accuracy/train_label_query_nway_accuracy', accs[\"label_query_nway\"][-1], step)\n",
    "            writer.add_scalar('Accuracy/train_unlabel_query_nway_accuracy', accs[\"unlabel_query_nway\"][-1], step)\n",
    "        if \"gan_query_nway\" in accs:\n",
    "            writer.add_scalar('Accuracy/train_gan_query_nway_accuracy', accs[\"gan_query_nway\"][-1], step)\n",
    "        if \"query_nway\" in accs:\n",
    "            writer.add_scalar('Accuracy/train_query_nway_accuracy', accs[\"query_nway\"][-1], step)\n",
    "        if step % 30 == 0:\n",
    "            print('step:', step, '\\ttraining acc:', accs)\n",
    "        if step % 100 == 0:  # evaluation\n",
    "            db_test = DataLoader(test_data_generator, 1, shuffle=True, num_workers=1, pin_memory=True)\n",
    "            accs_all_test = {\n",
    "                            \"total_query_nway\":[],\n",
    "                            \"unlabel_query_nway\":[],\n",
    "                            \"query_nway\":[],\n",
    "                            \"label_query_nway\":[],\n",
    "                            \"gan_query_nway\":[]\n",
    "            }\n",
    "\n",
    "            for test_data in db_test:\n",
    "                if args[\"gan\"]:\n",
    "                    gan_spt_noise = torch.randn(args[\"spy_gan_num\"], 100, 1, 1, device=device)\n",
    "                    gan_spt = netG(gan_spt_noise).to(device)\n",
    "                    gan_qry_noise = torch.randn(args[\"qry_gan_num\"], 100, 1, 1, device=device)\n",
    "                    gan_qry = netG(gan_qry_noise).to(device)\n",
    "                if len(test_data) == 4:\n",
    "                    x_spt, y_spt, x_qry, y_qry = test_data\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "                    if args[\"gan\"]:\n",
    "                        accs,loss_q = maml.finetunning(x_spt, y_spt, x_qry, y_qry,gan_spt=gan_spt, gan_qry=gan_qry)\n",
    "                    else:\n",
    "                        accs = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    \n",
    "                else:\n",
    "                    x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry = test_data\n",
    "                    x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device),\\\n",
    "                                                unlabel_spt.squeeze(0).to(device), unlabel_qry.squeeze(0).to(device)\n",
    "                    if args[\"gan\"]:\n",
    "                        accs = maml.finetunning(x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry,gan_spt=gan_spt, gan_qry=gan_qry)\n",
    "                    else:\n",
    "                        accs = maml.finetunning(x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry)\n",
    "                if \"total_query_nway\" in accs:\n",
    "                    accs_all_test[\"total_query_nway\"].append(accs[\"total_query_nway\"])\n",
    "                if \"label_query_nway\" in accs:\n",
    "                    accs_all_test[\"label_query_nway\"].append(accs[\"label_query_nway\"])\n",
    "                    accs_all_test[\"unlabel_query_nway\"].append(accs[\"unlabel_query_nway\"])\n",
    "                if \"gan_query_nway\" in accs:\n",
    "                    accs_all_test[\"gan_query_nway\"].append(accs[\"gan_query_nway\"])\n",
    "                if \"query_nway\" in accs:\n",
    "                    accs_all_test[\"query_nway\"].append(accs[\"query_nway\"])\n",
    "            # [b, update_step+1]\n",
    "            if \"total_query_nway\" in accs:\n",
    "                accs[\"total_query_nway\"] = np.array(accs_all_test[\"total_query_nway\"]).mean(axis=0).astype(np.float16)\n",
    "                writer.add_scalar('Accuracy/test_total_query_nway_accuracy', accs[\"total_query_nway\"][-1], step)\n",
    "            if \"label_query_nway\" in accs:\n",
    "                accs[\"label_query_nway\"] = np.array(accs_all_test[\"label_query_nway\"]).mean(axis=0).astype(np.float16)\n",
    "                accs[\"unlabel_query_nway\"] = np.array(accs_all_test[\"unlabel_query_nway\"]).mean(axis=0).astype(np.float16)\n",
    "                writer.add_scalar('Accuracy/test_label_query_nway_accuracy', accs[\"label_query_nway\"][-1], step)\n",
    "                writer.add_scalar('Accuracy/test_unlabel_query_nway_accuracy', accs[\"unlabel_query_nway\"][-1], step)\n",
    "            if \"gan_query_nway\" in accs:\n",
    "                accs[\"gan_query_nway\"] = np.array(accs_all_test[\"gan_query_nway\"]).mean(axis=0).astype(np.float16)\n",
    "                writer.add_scalar('Accuracy/test_gan_query_nway_accuracy', accs[\"gan_query_nway\"][-1], step)\n",
    "            if \"query_nway\" in accs:\n",
    "                accs[\"query_nway\"] = np.array(accs_all_test[\"query_nway\"]).mean(axis=0).astype(np.float16)\n",
    "                writer.add_scalar('Accuracy/test_query_nway_accuracy', accs[\"query_nway\"][-1], step)\n",
    "            \n",
    "            print(idx, 'Test acc:', accs)\n",
    "\n",
    "\n",
    "            torch.save(maml.state_dict(), \"maml/\" + path + \"/model_step\" + str(step) + \".pt\")\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f4a17-ca6e-47f6-8af2-3eebac477003",
   "metadata": {},
   "outputs": [],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc5790-6835-4dbf-bf28-e05434d83d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagan",
   "language": "python",
   "name": "metagan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
