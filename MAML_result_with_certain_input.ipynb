{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cf20f9-4ba4-4c03-a62a-39edf396473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch, os\n",
    "import  numpy as np\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "from    torch.optim import lr_scheduler\n",
    "import  random, sys, pickle\n",
    "from utils.results.dataloaders_2 import train_data_gen , test_data_gen\n",
    "# from maml_meta import Meta\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from    torch import optim\n",
    "from maml_learner import Learner\n",
    "from    torch.nn import functional as F\n",
    "from    copy import deepcopy\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c183b5-bd2c-402f-9e8c-4972c3107350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 60000, 'n_way': 5, 'k_spt': 5, 'k_qry': 10, 'data_augmentation_num': 3, 'img_sz': 84, 'task_num': 5, 'img_c': 3, 'meta_lr': 0.001, 'update_lr': 0.01, 'update_step': 5, 'update_step_test': 10, 'loss': 'cross_entropy', 'min_learning_rate': 1e-15, 'number_of_training_steps_per_iter': 5, 'multi_step_loss_num_epochs': 10, 'spy_gan_num': 1, 'qry_gan_num': 5, 'num_distractor': 2, 'gan': 0, 'spy_distractor_num': 1, 'qry_distractor_num': 15, 'batch_for_gradient': 25, 'fm': 32, 'no_save': 0, 'learn_inner_lr': 0, 'create_graph': 0, 'msl': 0, 'single_fast_test': 0, 'consine_schedule': 12000, 'eta_min': 1e-06, 'save_path': '5shot2distractor15_with_data_augmentation_test_guasian_noise_certain2'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"results_configs/5shot2distractor15_with_data_augmentation_test_guasian_noise_certain2.json\") as json_file:\n",
    "    args = json.load(json_file)\n",
    "print(args)\n",
    "if os.path.exists(\"maml_runs/\" + args[\"save_path\"]):\n",
    "    shutil.rmtree(\"maml_runs/\" + args[\"save_path\"])\n",
    "writer = SummaryWriter(\"results_runs/\" + args[\"save_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b15abd89-ef3e-4010-8b49-0c853b073abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFG 16\n",
      "DFG 18\n",
      "DFG 13\n",
      "DFG 17\n",
      "DFG 12\n",
      "DFG 13\n",
      "DFG 19\n",
      "DFG 13\n",
      "DFG 18\n",
      "DFG 14\n",
      "DFG 12\n",
      "DFG 12\n",
      "DFG 16\n",
      "DFG 17\n",
      "DFG 19\n",
      "DFG 15\n",
      "DFG 17\n",
      "DFG 18\n",
      "DFG 16\n",
      "DFG 13\n",
      "DFG 18\n",
      "DFG 11\n",
      "DFG 17\n",
      "DFG 16\n",
      "DFG 15\n",
      "DFG 14\n",
      "DFG 14\n",
      "DFG 17\n",
      "DFG 16\n",
      "DFG 17\n",
      "DFG 12\n",
      "DFG 17\n",
      "DFG 12\n",
      "DFG 17\n",
      "DFG 17\n",
      "DFG 13\n",
      "DFG 14\n",
      "DFG 17\n",
      "DFG 17\n",
      "DFG 16\n",
      "DFG 14\n",
      "DFG 19\n",
      "DFG 18\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "num = []\n",
    "\n",
    "for i in ([i for i in glob.iglob(\"datasets/GTSRB/test/*\",recursive=True)]):\n",
    "    if len(glob.glob(i + \"/*\")) < 20:\n",
    "        print(\"GTSRB\",len(glob.glob(i + \"/*\")))\n",
    "        num.append(len(glob.glob(i + \"/*\")))\n",
    "for i in ([i for i in glob.iglob(\"datasets/DFG/test/*\",recursive=True)]):\n",
    "    if len(glob.glob(i + \"/*\")) < 20:\n",
    "        print(\"DFG\",len(glob.glob(i + \"/*\")))\n",
    "        num.append(len(glob.glob(i + \"/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03c668ce-5136-4a74-b947-5a706c591650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(num).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12226c5c-9722-499f-b301-25709591a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_file = glob.glob(i + \"/*\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9fa08a-b78c-44f9-8638-cb702894d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    if not os.path.exists(\"model_results/\" + path):\n",
    "        os.makedirs(\"model_results/\" + path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d99e4cb-f139-4280-a099-4ebd2a9d2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE\n",
    "fm = args[\"fm\"]\n",
    "config = [\n",
    "    (\"conv2d\", [fm, 3, 3, 3, 1, 0]),\n",
    "    (\"leakyrelu\", [0.2,True]),\n",
    "    (\"bn\", [fm]),\n",
    "    (\"max_pool2d\", [2, 2, 0]),\n",
    "    (\"conv2d\", [fm, fm, 3, 3, 1, 0]),\n",
    "    (\"leakyrelu\", [0.2,True]),\n",
    "    (\"bn\", [fm]),\n",
    "    (\"max_pool2d\", [2, 2, 0]),\n",
    "    (\"conv2d\", [fm, fm, 3, 3, 1, 0]),\n",
    "    (\"leakyrelu\", [0.2,True]),\n",
    "    (\"bn\", [fm]),\n",
    "    (\"max_pool2d\", [2, 2, 0]),\n",
    "    (\"conv2d\", [fm, fm, 3, 3, 1, 0]),\n",
    "    (\"leakyrelu\", [0.2,True]),\n",
    "    (\"bn\", [fm]),\n",
    "    (\"max_pool2d\", [2, 1, 0]),\n",
    "    (\"flatten\", []),\n",
    "    (\"linear\", [6, fm * 5 * 5])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cdf48fa-c580-4192-8d5a-a15e0caa9b8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load datasets/BelgiumTSC\n",
      "load complete time 0.4149768352508545\n",
      "load datasets/ArTS\n",
      "load complete time 0.39762187004089355\n",
      "load datasets/chinese_traffic_sign\n",
      "load complete time 0.7308413982391357\n",
      "load datasets/CVL\n",
      "load complete time 0.5714128017425537\n",
      "load datasets/FullJCNN2013\n",
      "load complete time 0.2766551971435547\n",
      "load datasets/logo_2k\n",
      "load complete time 1.0395228862762451\n",
      "load datasets/GTSRB\n",
      "load complete time 0.09952497482299805\n",
      "load datasets/DFG\n",
      "load complete time 0.034998178482055664\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = train_data_gen(args)\n",
    "test_data_generator = test_data_gen(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fec54d1-d92d-4be4-82f6-ae63411b94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt\n",
    "# train_dataloader = DataLoader(train_data_generator, args[\"task_num\"], shuffle=True, num_workers=1, pin_memory=True)\n",
    "# for idx,data  in enumerate(train_dataloader):\n",
    "#     (x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry) = data\n",
    "#     break\n",
    "# invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "#                                                      std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "#                                 transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "#                                                      std = [ 1., 1., 1. ])])\n",
    "# inv_tensor = invTrans(x_spt[0])\n",
    "\n",
    "#     # break\n",
    "# # for i in range(len(unlabel_spt)):\n",
    "# #     for j in range(len(unlabel_spt[i])):\n",
    "# #         img = (unlabel_spt[i][j])\n",
    "# #         img = invTrans(img)\n",
    "# #         plt.figure()\n",
    "# #         plt.imshow(img.numpy().transpose(1,2,0))\n",
    "# #         plt.show()\n",
    "# #         # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e9c8db-07b2-4b9d-876c-440bbac3e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from    PIL import Image\n",
    "# class gaussian_noise(object):\n",
    "    \n",
    "#     def __init__(self,mean=0,sigma=0.1):\n",
    "#         self.mean = np.random.uniform(0,0.25)\n",
    "#         self.sigma = np.random.uniform(0.1,0.01)\n",
    "        \n",
    "#     def __call__(self,img):\n",
    "       \n",
    "#         if np.random.randint(0,2):\n",
    "#             img = np.array(img) / 255.\n",
    "\n",
    "#             h,w,c = img.shape\n",
    "\n",
    "#             noise = np.random.normal(self.mean, self.sigma, img.shape) # 隨機生成高斯 noise (float + float)\n",
    "#             # noise + 原圖\n",
    "#             gaussian_out = img + noise\n",
    "#             # 所有值必須介於 0~1 之間，超過1 = 1，小於0 = 0\n",
    "#             gaussian_out = np.clip(gaussian_out, 0, 1)\n",
    "\n",
    "#             # 原圖: float -> int (0~1 -> 0~255)\n",
    "#             gaussian_out = np.uint8(gaussian_out*255)\n",
    "#             # noise: float -> int (0~1 -> 0~255)\n",
    "#             gaussian_out = Image.fromarray(gaussian_out, 'RGB')\n",
    "        \n",
    "#             return gaussian_out\n",
    "#         else:\n",
    "#             return img\n",
    "        \n",
    "# transform = transforms.Compose([lambda x: Image.open(x).convert('RGB'),\n",
    "#                                      # transforms.FiveCrop(self.resize),\n",
    "#                                      transforms.Resize((84, 84)),\n",
    "#                                      gaussian_noise(mean=0,sigma=0.1),\n",
    "#                                      # transforms.RandomHorizontalFlip(),\n",
    "#                                      transforms.RandomRotation(5),\n",
    "#                                      transforms.ToTensor(),\n",
    "#                                      # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "#                                      ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a858946b-68a2-4e05-99f2-00ce2df7b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlabel_spt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8333d9ae-7a75-424d-9ae5-f55b52d16da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(train_data_generator, args[\"task_num\"], shuffle=True, num_workers=1, pin_memory=True)\n",
    "# for idx,data  in enumerate(train_dataloader):\n",
    "#     (x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry) = data\n",
    "#     plt.figure()\n",
    "#     fig, axarr = plt.subplots(unlabel_spt.size(0), unlabel_spt.size(1),figsize=(15, 5))\n",
    "#     k = 1\n",
    "#     for i in range(len(unlabel_spt)):\n",
    "#         for j in range(len(unlabel_spt[i])):\n",
    "#             # print(i)\n",
    "#             img = (unlabel_spt[i][j])\n",
    "#             img = invTrans(img)\n",
    "#             plt.axis(\"off\")\n",
    "\n",
    "#             # fig.add_subplot(x_spt.size(0), x_spt.size(1), k)\n",
    "#             k = k + 1\n",
    "#             axarr[i,j].imshow(img.numpy().transpose(1,2,0))\n",
    "#             axarr[i,j].axis('off')\n",
    "#     plt.show()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2fd1204-c55d-4d90-9335-1d05e905b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_file = 'datasets/BelgiumTSC/train/00011/02424_00001.jpg'\n",
    "# img = transform(img_file)\n",
    "# img = invTrans(img)\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# # fig.add_subplot(x_spt.size(0), x_spt.size(1), k)\n",
    "# k = k + 1\n",
    "# plt.imshow(img.numpy().transpose(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac58460c-1510-4ab5-95ed-72eb68d3d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(train_data_generator, args[\"task_num\"], shuffle=True, num_workers=1, pin_memory=True)\n",
    "# for idx,data  in enumerate(train_dataloader):\n",
    "#     (x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry) = data\n",
    "\n",
    "#     fig, axarr = plt.subplots(x_spt.size(0), x_spt.size(1),figsize=(15, 5))\n",
    "#     k = 1\n",
    "#     for i in range(len(x_spt)):\n",
    "#         for j in range(len(x_spt[i])):\n",
    "#             # print(i)\n",
    "#             img = (x_spt[i][j])\n",
    "#             img = invTrans(img)\n",
    "#             plt.axis(\"off\")\n",
    "\n",
    "#             # fig.add_subplot(x_spt.size(0), x_spt.size(1), k)\n",
    "#             k = k + 1\n",
    "#             axarr[i,j].imshow(img.numpy().transpose(1,2,0))\n",
    "#             axarr[i,j].axis('off')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e9a5621-204f-4563-92f0-f3550c850868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Meta(nn.Module):\n",
    "    \"\"\"\n",
    "    Meta Learner\n",
    "    \"\"\"\n",
    "    def __init__(self, args, config):\n",
    "        \"\"\"\n",
    "\n",
    "        :param args:\n",
    "        \"\"\"\n",
    "        super(Meta, self).__init__()\n",
    "\n",
    "        self.update_lr = args[\"update_lr\"]\n",
    "        self.meta_lr = args[\"meta_lr\"]\n",
    "        self.n_way = args[\"n_way\"]\n",
    "        self.k_spt = args[\"k_spt\"]\n",
    "        self.k_qry = args[\"k_qry\"]\n",
    "        self.task_num = args[\"task_num\"]\n",
    "        self.update_step = args[\"update_step\"]\n",
    "        self.update_step_test = args[\"update_step_test\"]\n",
    "        self.distractor = args[\"num_distractor\"]\n",
    "        self.net = Learner(config, args[\"img_c\"], args[\"img_sz\"])\n",
    "        self.meta_optim = optim.Adam(self.net.parameters(), lr=self.meta_lr)\n",
    "        if args[\"consine_schedule\"]:\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.meta_optim, T_max=args[\"consine_schedule\"], eta_min=args[\"eta_min\"])\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        self.gan = args[\"gan\"]\n",
    "        self.multi_step_loss_num_epochs = args[\"multi_step_loss_num_epochs\"]\n",
    "        \n",
    "    def get_per_step_loss_importance_vector(self):\n",
    "\n",
    "        loss_weights = np.ones(shape=(self.update_step)) * (\n",
    "                1.0 / self.update_step)\n",
    "        decay_rate = 1.0 / self.update_step / self.multi_step_loss_num_epochs\n",
    "        min_value_for_non_final_losses = 0.03 / self.update_step\n",
    "        for i in range(len(loss_weights) - 1):\n",
    "            curr_value = np.maximum(loss_weights[i] - (self.current_epoch * decay_rate), min_value_for_non_final_losses)\n",
    "            loss_weights[i] = curr_value\n",
    "\n",
    "        curr_value = np.minimum(\n",
    "            loss_weights[-1] + (self.current_epoch * (self.update_step - 1) * decay_rate),\n",
    "            1.0 - ((self.update_step - 1) * min_value_for_non_final_losses))\n",
    "        loss_weights[-1] = curr_value\n",
    "        loss_weights = torch.Tensor(loss_weights).to(device=self.device)\n",
    "        return loss_weights\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry, current_epoch,unlabel_spt_image=None, unlabel_qry_image=None,gan_spt=None, gan_qry=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x_spt:   [b, setsz, c_, h, w]\n",
    "        :param y_spt:   [b, setsz]\n",
    "        :param x_qry:   [b, querysz, c_, h, w]\n",
    "        :param y_qry:   [b, querysz]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.current_epoch = current_epoch\n",
    "        per_step_loss_importance_vectors = self.get_per_step_loss_importance_vector()\n",
    "        task_num, setsz, c_, h, w = x_spt.size()\n",
    "        querysz = x_qry.size(1)\n",
    "        if self.gan :\n",
    "            gan_sptsz = gan_spt.size(1)\n",
    "            gan_qrysz = gan_qry.size(1)\n",
    "        else:\n",
    "            gan_sptsz = 0\n",
    "            gan_qrysz = 0\n",
    "        if self.distractor or self.gan:\n",
    "            corrects = {}\n",
    "            corrects[\"total_query_nway\"] = np.zeros(self.update_step + 1)\n",
    "            if self.distractor:\n",
    "                unlabel_querysz = unlabel_qry.size(1)\n",
    "                corrects[\"query_nway_recall\"] = np.zeros(self.update_step + 1)\n",
    "                corrects[\"label_query_nway_recall\"] = np.zeros(self.update_step + 1)\n",
    "                corrects[\"distractor_query_nway_recall\"] = np.zeros(self.update_step + 1)\n",
    "            if self.gan :\n",
    "                corrects[\"gan_query_nway\"] = np.zeros(self.update_step + 1)\n",
    "        else:\n",
    "            corrects = {key: np.zeros(self.update_step + 1) for key in \n",
    "                [\n",
    "                \"query_nway_recall\",\n",
    "                \"label_query_nway_recall\"\n",
    "                ]}\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]  # losses_q[i] is the loss on step i\n",
    "\n",
    "        for i in range(task_num):\n",
    "            spt_image = x_spt[i]\n",
    "            spt_label = y_spt[i]\n",
    "            qry_image = x_qry[i]\n",
    "            qry_label = y_qry[i]\n",
    "            if self.distractor:\n",
    "                spt_image = torch.concat((spt_image,unlabel_spt[i]))\n",
    "                spt_unlabel_label = torch.full((unlabel_spt.size(1),), 5, dtype=torch.long,device=self.device)\n",
    "                spt_label = torch.cat((spt_label,spt_unlabel_label))\n",
    "                qry_image = torch.concat((qry_image,unlabel_qry[i]))\n",
    "                qry_unlabel_label = torch.full((unlabel_qry.size(1),), 5, dtype=torch.long,device=self.device)\n",
    "                qry_label = torch.cat((qry_label,qry_unlabel_label))\n",
    "            if self.gan :\n",
    "                spt_image = torch.concat((spt_image,gan_spt[i]))\n",
    "                spt_gan_label = torch.full((gan_spt.size(1),), 5, dtype=torch.long,device=self.device)\n",
    "                spt_label = torch.cat((spt_label,spt_gan_label))\n",
    "                qry_image = torch.concat((qry_image,gan_qry[i]))\n",
    "                qry_gan_label = torch.full((gan_qry.size(1),), 5, dtype=torch.long,device=self.device)\n",
    "                qry_label = torch.cat((qry_label,qry_gan_label))\n",
    "\n",
    "            # 1. run the i-th task and compute loss for k=0\n",
    "            logits = self.net(spt_image, vars=None, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, spt_label)\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, self.net.parameters())))\n",
    "\n",
    "            # this is the loss and accuracy before first update\n",
    "            with torch.no_grad():\n",
    "                # [setsz, nway]\n",
    "                if self.distractor or self.gan:\n",
    "                    total_logits_q = self.net(qry_image, self.net.parameters(), bn_training=False)\n",
    "                    total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                    total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                    corrects[\"total_query_nway\"][0] += total_q_correct\n",
    "                    loss_q = F.cross_entropy(total_logits_q, qry_label)\n",
    "                    losses_q[0] += loss_q\n",
    "                    if self.distractor:\n",
    "                        label_logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=False)\n",
    "                        label_pred_q = F.softmax(label_logits_q, dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                        corrects[\"label_query_nway_recall\"][0] += label_pred_q_correct\n",
    "                        label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                        corrects[\"query_nway_recall\"][0] += label_pred_q_correct\n",
    "                        \n",
    "\n",
    "                        unlabel_logits_q = self.net(unlabel_qry[i], self.net.parameters(), bn_training=False)\n",
    "                        unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                        other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                        corrects[\"distractor_query_nway_recall\"][0] += other\n",
    "                    if self.gan :\n",
    "                        gan_logits_q = self.net(gan_qry[i], self.net.parameters(), bn_training=False)\n",
    "                        gan_pred_q = F.softmax(gan_logits_q, dim=1).argmax(dim=1)\n",
    "                        gan_counts = torch.eq(gan_pred_q, qry_gan_label).sum().item()\n",
    "                        corrects[\"gan_query_nway\"][0] += gan_counts\n",
    "                else:\n",
    "                    logits_q = self.net(qry_image, self.net.parameters(), bn_training=True)\n",
    "                    loss_q = F.cross_entropy(logits_q, qry_label)\n",
    "                    pred_q = F.softmax(logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                    q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                    corrects[\"query_nway_recall\"][0] += q_discrim_correct\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                    corrects[\"label_query_nway_recall\"][0] += q_discrim_correct\n",
    "                    losses_q[0] += loss_q\n",
    "            # this is the loss and accuracy after the first update\n",
    "            with torch.no_grad():\n",
    "                # [setsz, nway]\n",
    "                if self.distractor or self.gan:\n",
    "                    \n",
    "                    total_logits_q = self.net(qry_image,fast_weights , bn_training=False)\n",
    "                    total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                    total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                    corrects[\"total_query_nway\"][1] += total_q_correct\n",
    "                    loss_q = F.cross_entropy(total_logits_q, qry_label)\n",
    "                    losses_q[1] += loss_q\n",
    "                    if self.distractor:\n",
    "                        label_logits_q = self.net(x_qry[i], fast_weights, bn_training=False)\n",
    "                        label_pred_q = F.softmax(label_logits_q, dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                        corrects[\"label_query_nway_recall\"][1] += label_pred_q_correct\n",
    "                        label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                        label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                        corrects[\"query_nway_recall\"][1] += label_pred_q_correct\n",
    "                        \n",
    "                        unlabel_logits_q = self.net(unlabel_qry[i], fast_weights, bn_training=False)\n",
    "                        unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                        other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                        corrects[\"distractor_query_nway_recall\"][1] += other\n",
    "                    if self.gan :\n",
    "                        gan_logits_q = self.net(gan_qry[i], fast_weights, bn_training=False)\n",
    "                        gan_pred_q = F.softmax(gan_logits_q, dim=1).argmax(dim=1)\n",
    "                        gan_counts = torch.eq(gan_pred_q, qry_gan_label).sum().item()\n",
    "                        corrects[\"gan_query_nway\"][1] += gan_counts\n",
    "                else:\n",
    "                    logits_q = self.net(qry_image, fast_weights, bn_training=False)\n",
    "                    loss_q = F.cross_entropy(logits_q, qry_label)\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                    corrects[\"query_nway_recall\"][1] += q_discrim_correct\n",
    "                    pred_q = F.softmax(logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                    q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                    corrects[\"label_query_nway_recall\"][1] += q_discrim_correct\n",
    "                    losses_q[1] += loss_q\n",
    "\n",
    "            for k in range(1, self.update_step):\n",
    "                # 1. run the i-th task and compute loss for k=1~K-1\n",
    "                logits = self.net(spt_image, fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(logits, spt_label)\n",
    "                # 2. compute grad on theta_pi\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                # 3. theta_pi = theta_pi - train_lr * grad\n",
    "                fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n",
    "\n",
    "                logits_q = self.net(qry_image, fast_weights, bn_training=True)\n",
    "                # loss_q will be overwritten and just keep the loss_q on last update step.\n",
    "                loss_q = F.cross_entropy(logits_q, qry_label)\n",
    "                losses_q[k + 1] += loss_q\n",
    "                with torch.no_grad():\n",
    "                    if self.distractor or self.gan:\n",
    "                        total_logits_q = self.net(qry_image, fast_weights, bn_training=False)\n",
    "                        total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                        total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                        corrects[\"total_query_nway\"][k+1] += total_q_correct\n",
    "                        if self.distractor:\n",
    "                            label_logits_q = self.net(x_qry[i], fast_weights, bn_training=False)\n",
    "                            label_pred_q = F.softmax(label_logits_q, dim=1).argmax(dim=1)\n",
    "                            label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                            corrects[\"label_query_nway_recall\"][k+1] += label_pred_q_correct\n",
    "                            label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                            label_pred_q_correct = torch.eq(label_pred_q, y_qry[i]).sum().item()\n",
    "                            corrects[\"query_nway_recall\"][k+1] += label_pred_q_correct\n",
    "                            \n",
    "                            unlabel_logits_q = self.net(unlabel_qry[i], fast_weights, bn_training=False)\n",
    "                            unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                            other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                            corrects[\"distractor_query_nway_recall\"][k+1] += other\n",
    "                        if self.gan :\n",
    "                            gan_logits_q = self.net(gan_qry[i], fast_weights, bn_training=False)\n",
    "                            gan_pred_q = F.softmax(gan_logits_q, dim=1).argmax(dim=1)\n",
    "                            gan_counts = torch.eq(gan_pred_q, qry_gan_label).sum().item()\n",
    "                            corrects[\"gan_query_nway\"][k+1] += gan_counts\n",
    "                    else:\n",
    "                        pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                        q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                        corrects[\"query_nway_recall\"][k+1] += q_discrim_correct\n",
    "                        pred_q = F.softmax(logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                        q_discrim_correct = torch.eq(pred_q, qry_label).sum().item()\n",
    "                        corrects[\"label_query_nway_recall\"][k+1] += q_discrim_correct\n",
    "        # end of all tasks\n",
    "        # sum over all losses on query set across all tasks\n",
    "        loss_q = 0\n",
    "\n",
    "        for num_step, loss in enumerate(losses_q[1:]):\n",
    "            loss_q = loss_q + per_step_loss_importance_vectors[num_step] * loss / task_num\n",
    "        # optimize theta parameters\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.backward()\n",
    "\n",
    "        self.meta_optim.step()\n",
    "        \n",
    "        accs = {}\n",
    "        if (self.distractor or self.gan):\n",
    "            accs[\"total_query_nway\"] = corrects[\"total_query_nway\"] / (task_num * (querysz + unlabel_querysz + gan_qrysz))\n",
    "            if self.distractor:\n",
    "                accs[\"label_query_nway_recall\"] = corrects[\"label_query_nway_recall\"] / (task_num * querysz)\n",
    "                accs[\"query_nway_recall\"] = corrects[\"query_nway_recall\"] / (task_num * querysz)\n",
    "                accs[\"distractor_query_nway_recall\"] = corrects[\"distractor_query_nway_recall\"] / (task_num * unlabel_querysz)\n",
    "            if gan_qrysz:\n",
    "                accs[\"gan_query_nway\"] = corrects[\"gan_query_nway\"] / (task_num * gan_qrysz)\n",
    "        else:\n",
    "            accs[\"query_nway_recall\"] = corrects[\"query_nway_recall\"] / (task_num * querysz)\n",
    "            accs[\"label_query_nway_recall\"] = corrects[\"label_query_nway_recall\"] / (task_num * querysz)\n",
    "        return accs,loss_q\n",
    "\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry, unlabel_spt=None, unlabel_qry=None, gan_spt=None, gan_qry=None):\n",
    "\n",
    "        assert len(x_spt.shape) == 4\n",
    "        querysz = x_qry.size(0)\n",
    "\n",
    "        corrects = {}\n",
    "        corrects[\"total_query_nway\"] = np.zeros(self.update_step_test + 1)\n",
    "\n",
    "        unlabel_querysz = unlabel_qry.size(0)\n",
    "\n",
    "        corrects[\"query_nway_recall\"] = np.zeros(self.update_step_test + 1)\n",
    "        corrects[\"distractor_query_nway_recall\"] = np.zeros(self.update_step_test + 1)\n",
    "\n",
    "        # in order to not ruin the state of running_mean/variance and bn_weight/bias\n",
    "        # we finetunning on the copied model instead of self.net\n",
    "        net = deepcopy(self.net)\n",
    "        spt_image = x_spt\n",
    "        spt_label = y_spt\n",
    "        qry_image = x_qry\n",
    "        qry_label = y_qry\n",
    "        if self.distractor:\n",
    "            spt_image = torch.concat((spt_image,unlabel_spt))\n",
    "            spt_unlabel_label = torch.full((unlabel_spt.size(0),), 5, dtype=torch.long,device=self.device)\n",
    "            spt_label = torch.cat((spt_label,spt_unlabel_label))\n",
    "\n",
    "        qry_image = torch.concat((qry_image,unlabel_qry))\n",
    "        qry_unlabel_label = torch.full((unlabel_qry.size(0),), 5, dtype=torch.long,device=self.device)\n",
    "        qry_label = torch.cat((qry_label,qry_unlabel_label))\n",
    "\n",
    "        # 1. run the i-th task and compute loss for k=0\n",
    "        logits = net(spt_image)\n",
    "        loss = F.cross_entropy(logits, spt_label)\n",
    "\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters())))\n",
    "\n",
    "        # this is the loss and accuracy before first update\n",
    "        with torch.no_grad():\n",
    "\n",
    "            total_logits_q = self.net(qry_image,self.net.parameters() , bn_training=False)\n",
    "            total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "            total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "            corrects[\"total_query_nway\"][1] += total_q_correct\n",
    "            loss_q = F.cross_entropy(total_logits_q, qry_label)\n",
    "\n",
    "            label_logits_q = self.net(x_qry, self.net.parameters(), bn_training=False)\n",
    "            label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "            label_pred_q_correct = torch.eq(label_pred_q, y_qry).sum().item()\n",
    "            corrects[\"query_nway_recall\"][0] += label_pred_q_correct\n",
    "\n",
    "            unlabel_logits_q = self.net(unlabel_qry, self.net.parameters(), bn_training=False)\n",
    "            unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "            other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "            corrects[\"distractor_query_nway_recall\"][0] += other\n",
    "\n",
    "\n",
    "        # this is the loss and accuracy after the first update\n",
    "        with torch.no_grad():\n",
    "\n",
    "            total_logits_q = self.net(qry_image,fast_weights , bn_training=False)\n",
    "            total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "            \n",
    "            total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "            corrects[\"total_query_nway\"][1] += total_q_correct\n",
    "            loss_q = F.cross_entropy(total_logits_q, qry_label)\n",
    "\n",
    "            label_logits_q = self.net(x_qry, fast_weights, bn_training=False)\n",
    "            label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "            label_pred_q_correct = torch.eq(label_pred_q, y_qry).sum().item()\n",
    "            corrects[\"query_nway_recall\"][1] += label_pred_q_correct\n",
    "\n",
    "            unlabel_logits_q = self.net(unlabel_qry, fast_weights, bn_training=False)\n",
    "            \n",
    "            unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "            other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "            corrects[\"distractor_query_nway_recall\"][1] += other\n",
    "\n",
    "\n",
    "        for k in range(1, self.update_step_test):\n",
    "            # 1. run the i-th task and compute loss for k=1~K-1\n",
    "            logits = net(spt_image, fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, spt_label)\n",
    "            # 2. compute grad on theta_pi\n",
    "            grad = torch.autograd.grad(loss, fast_weights)\n",
    "            # 3. theta_pi = theta_pi - train_lr * grad\n",
    "            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n",
    "\n",
    "            logits_q = net(qry_image, fast_weights, bn_training=True)\n",
    "            # loss_q will be overwritten and just keep the loss_q on last update step.\n",
    "            loss_q = F.cross_entropy(logits_q, qry_label)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                total_logits_q = self.net(qry_image,fast_weights , bn_training=False)\n",
    "\n",
    "                total_pred_q = F.softmax(total_logits_q, dim=1).argmax(dim=1)\n",
    "                total_q_correct = torch.eq(total_pred_q, qry_label).sum().item()\n",
    "                corrects[\"total_query_nway\"][k+1] += total_q_correct\n",
    "                loss_q = F.cross_entropy(total_logits_q, qry_label)\n",
    "\n",
    "                label_logits_q = self.net(x_qry, fast_weights, bn_training=False)\n",
    "                label_pred_q = F.softmax(label_logits_q[:,:-1], dim=1).argmax(dim=1)\n",
    "                label_pred_q_correct = torch.eq(label_pred_q, y_qry).sum().item()\n",
    "                corrects[\"query_nway_recall\"][k+1] += label_pred_q_correct\n",
    "\n",
    "                unlabel_logits_q = self.net(unlabel_qry, fast_weights, bn_training=False)\n",
    "                unlabel_pred_q = F.softmax(unlabel_logits_q, dim=1).argmax(dim=1)\n",
    "                other = torch.eq(unlabel_pred_q, qry_unlabel_label).sum().item()\n",
    "                corrects[\"distractor_query_nway_recall\"][k+1] += other\n",
    "        del net\n",
    "        accs = {}\n",
    "\n",
    "        accs[\"total_query_nway\"] = corrects[\"total_query_nway\"] / (querysz + unlabel_querysz)\n",
    "        accs[\"query_nway_recall\"] = corrects[\"query_nway_recall\"] / querysz\n",
    "        accs[\"distractor_query_nway_recall\"] = corrects[\"distractor_query_nway_recall\"] / (unlabel_querysz)\n",
    "\n",
    "        return accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deb2d02e-c650-4a07-b2ce-5ab10edf5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "maml = Meta(args, config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecadcd4d-b5a1-4e2d-9648-e716f71db135",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "num = sum(map(lambda x: np.prod(x.shape), tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38236a4e-eb80-4c04-9cd8-21792e4f05b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: {'total_query_nway': array([0.205 , 0.3225, 0.425 , 0.465 , 0.525 , 0.56  ]), 'label_query_nway_recall': array([0.24 , 0.428, 0.572, 0.624, 0.676, 0.72 ]), 'query_nway_recall': array([0.256, 0.436, 0.576, 0.624, 0.688, 0.736]), 'distractor_query_nway_recall': array([0.14666667, 0.14666667, 0.18      , 0.2       , 0.27333333,\n",
      "       0.29333333])}\n",
      "Test acc: {'total_query_nway': array([0.    , 0.527 , 0.4443, 0.4712, 0.4941, 0.511 , 0.521 , 0.5283,\n",
      "       0.534 , 0.537 , 0.54  ], dtype=float16), 'query_nway_recall': array([0.2   , 0.4277, 0.529 , 0.557 , 0.5806, 0.596 , 0.606 , 0.6123,\n",
      "       0.6177, 0.621 , 0.625 ], dtype=float16), 'distractor_query_nway_recall': array([0.4163, 0.3062, 0.27  , 0.265 , 0.2588, 0.2688, 0.2725, 0.2688,\n",
      "       0.2737, 0.275 , 0.2688], dtype=float16)}\n",
      "step: 30 \ttraining acc: {'total_query_nway': array([0.125, 0.125, 0.125, 0.125, 0.125, 0.125]), 'label_query_nway_recall': array([0.2, 0.2, 0.2, 0.2, 0.2, 0.2]), 'query_nway_recall': array([0.2, 0.2, 0.2, 0.2, 0.2, 0.2]), 'distractor_query_nway_recall': array([0., 0., 0., 0., 0., 0.])}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_data_generator, args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_num\u001b[39m\u001b[38;5;124m\"\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m x_spt \u001b[38;5;241m=\u001b[39m y_spt \u001b[38;5;241m=\u001b[39m x_qry \u001b[38;5;241m=\u001b[39m y_qry \u001b[38;5;241m=\u001b[39m unlabel_spt \u001b[38;5;241m=\u001b[39m unlabel_qry \u001b[38;5;241m=\u001b[39m gan_qry \u001b[38;5;241m=\u001b[39m gan_spt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx,data  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m     11\u001b[0m         (x_spt, y_spt, x_qry, y_qry) \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniconda3/envs/metagan/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/metagan/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1207\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/metagan/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1163\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1165\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/metagan/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/metagan/lib/python3.8/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/envs/metagan/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = args[\"save_path\"]\n",
    "step = 0\n",
    "mkdir_p(path)\n",
    "for epoch in range(args[\"epoch\"]//6000):\n",
    "        # fetch meta_batchsz num of episode each time\n",
    "\n",
    "    train_dataloader = DataLoader(train_data_generator, args[\"task_num\"], shuffle=True, num_workers=1, pin_memory=True)\n",
    "    x_spt = y_spt = x_qry = y_qry = unlabel_spt = unlabel_qry = gan_qry = gan_spt = 0\n",
    "    for idx,data  in enumerate(train_dataloader):\n",
    "        if len(data) == 4:\n",
    "            (x_spt, y_spt, x_qry, y_qry) = data\n",
    "            x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "            if args[\"gan\"]:\n",
    "                accs,loss_q = maml(x_spt, y_spt, x_qry, y_qry,step,gan_spt=gan_spt, gan_qry=gan_qry)\n",
    "            else:\n",
    "                accs,loss_q = maml(x_spt, y_spt, x_qry, y_qry,step)\n",
    "        else:\n",
    "            (x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry) = data\n",
    "            x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device), \\\n",
    "            unlabel_spt.to(device), unlabel_qry.to(device)\n",
    "            if args[\"spy_gan_num\"]:\n",
    "                accs,loss_q = maml(x_spt, y_spt, x_qry, y_qry,step,unlabel_spt_image=unlabel_spt, unlabel_qry_image=unlabel_qry,gan_spt=gan_spt, gan_qry=gan_qry)\n",
    "            else:\n",
    "                accs,loss_q = maml(x_spt, y_spt, x_qry, y_qry,step,unlabel_spt_image=unlabel_spt, unlabel_qry_image=unlabel_qry)\n",
    "\n",
    "        writer.add_scalar(\"Loss/train_loss\", loss_q, step)\n",
    "        if \"total_query_nway\" in accs:\n",
    "            writer.add_scalar(\"Accuracy/train_total_query_nway\", accs[\"total_query_nway\"][-1], step)\n",
    "        if \"label_query_nway_recall\" in accs:\n",
    "            writer.add_scalar(\"Accuracy/train_label_query_nway_recall\", accs[\"label_query_nway_recall\"][-1], step)\n",
    "        if \"distractor_query_nway_recall\" in accs:\n",
    "            writer.add_scalar(\"Accuracy/train_distractor_query_nway_recall\", accs[\"distractor_query_nway_recall\"][-1], step)\n",
    "        if \"query_nway_recall\" in accs:\n",
    "            writer.add_scalar(\"Accuracy/train_query_nway_recall\", accs[\"query_nway_recall\"][-1], step)\n",
    "        if \"gan_query_nway_recall\" in accs:\n",
    "            writer.add_scalar(\"Accuracy/train_gan_query_nway_recall\", accs[\"gan_query_nway_recall\"][-1], step)\n",
    "        if \"query_nway\" in accs:\n",
    "            writer.add_scalar(\"Accuracy/train_query_nway_recall\", accs[\"query_nway_recall\"][-1], step)\n",
    "        if step % 30 == 0:\n",
    "            print(\"step:\", step, \"\\ttraining acc:\", accs)\n",
    "        if step % 100 == 0:  # evaluation\n",
    "            db_test = DataLoader(test_data_generator, 1, shuffle=True, num_workers=1, pin_memory=True)\n",
    "            accs_all_test = {\n",
    "                            \"total_query_nway\":[],\n",
    "                            \"distractor_query_nway_recall\":[],\n",
    "                            \"query_nway_recall\":[],\n",
    "                            \"label_query_nway_recall\":[],\n",
    "                            \"gan_query_nway\":[]\n",
    "            }\n",
    "            for test_data in db_test:\n",
    "\n",
    "                if len(test_data) == 4:\n",
    "                    x_spt, y_spt, x_qry, y_qry = test_data\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "\n",
    "                    accs = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "                else:\n",
    "                    x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry = test_data\n",
    "                    x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device),\\\n",
    "                                                unlabel_spt.squeeze(0).to(device), unlabel_qry.squeeze(0).to(device)\n",
    "\n",
    "\n",
    "                    accs = maml.finetunning(x_spt, y_spt, x_qry, y_qry, unlabel_spt, unlabel_qry)\n",
    "                if \"total_query_nway\" in accs:\n",
    "                    accs_all_test[\"total_query_nway\"].append(accs[\"total_query_nway\"])\n",
    "                if \"label_query_nway_recall\" in accs:\n",
    "                    accs_all_test[\"label_query_nway_recall\"].append(accs[\"label_query_nway_recall\"])\n",
    "                if \"distractor_query_nway_recall\" in accs:\n",
    "                    accs_all_test[\"distractor_query_nway_recall\"].append(accs[\"distractor_query_nway_recall\"])\n",
    "                if \"gan_query_nway\" in accs:\n",
    "                    accs_all_test[\"gan_query_nway\"].append(accs[\"gan_query_nway\"])\n",
    "                if \"query_nway_recall\" in accs:\n",
    "                    accs_all_test[\"query_nway_recall\"].append(accs[\"query_nway_recall\"])\n",
    "            # [b, update_step+1]\n",
    "            if \"total_query_nway\" in accs:\n",
    "                accs[\"total_query_nway\"] = np.array(accs_all_test[\"total_query_nway\"]).mean(axis=0).astype(np.float16)\n",
    "                writer.add_scalar(\"Accuracy/test_total_query_nway_accuracy\", accs[\"total_query_nway\"][-1], step)\n",
    "            if \"label_query_nway_recall\" in accs:\n",
    "                accs[\"label_query_nway_recall\"] = np.array(accs_all_test[\"label_query_nway_recall\"]).mean(axis=0).astype(np.float16)\n",
    "                \n",
    "                writer.add_scalar(\"Accuracy/test_label_query_nway_accuracy\", accs[\"label_query_nway_recall\"][-1], step)\n",
    "            if \"distractor_query_nway_recall\" in accs:\n",
    "                accs[\"distractor_query_nway_recall\"] = np.array(accs_all_test[\"distractor_query_nway_recall\"]).mean(axis=0).astype(np.float16)\n",
    "                writer.add_scalar(\"Accuracy/test_distractor_query_nway_recall_accuracy\", accs[\"distractor_query_nway_recall\"][-1], step)\n",
    "            if \"gan_query_nway\" in accs:\n",
    "                accs[\"gan_query_nway\"] = np.array(accs_all_test[\"gan_query_nway\"]).mean(axis=0).astype(np.float16)\n",
    "                writer.add_scalar(\"Accuracy/test_gan_query_nway_accuracy\", accs[\"gan_query_nway\"][-1], step)\n",
    "            if \"query_nway_recall\" in accs:\n",
    "                accs[\"query_nway_recall\"] = np.array(accs_all_test[\"query_nway_recall\"]).mean(axis=0).astype(np.float16)\n",
    "                writer.add_scalar(\"Accuracy/test_query_nway_accuracy\", accs[\"query_nway_recall\"][-1], step)\n",
    "\n",
    "            print(\"Test acc:\", accs)\n",
    "\n",
    "            torch.save(maml.state_dict(), \"model_results/\" + path + \"/model_step\" + str(step) + \".pt\")\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df969b2-8b84-42be-b214-e020d124c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769bd609-1888-4523-9336-9ed58ad53222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "values = np.array([1,2,3,1,2,4,5,6,3,2,1])\n",
    "searchval = 3\n",
    "np.where(values == searchval)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18240835-1b73-463f-b7c4-d6e50becf8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice([5, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2804a2-3ff1-4a7f-9d7e-1e579ac0e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_spt[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc915c4a-7c38-43e1-b835-b9600e0953b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                     std = [ 1., 1., 1. ])])\n",
    "inv_tensor = invTrans(x_spt[0])\n",
    "for i in range(len(x_spt[0])):\n",
    "    print(i)\n",
    "    i = (x_spt[2][i])\n",
    "    # i = (i*255).long()\n",
    "    plt.figure()\n",
    "    plt.imshow(i.cpu().numpy().transpose(1,2,0))\n",
    "    plt.show()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a84662-4834-4dac-9314-53ab8cfee4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_spt[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ec928-60f1-4f8a-8ffb-6e29a58e698c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagan",
   "language": "python",
   "name": "metagan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
