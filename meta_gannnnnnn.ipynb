{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9034beb-c9ed-4806-bef5-c1334415cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch\n",
    "from    torch import nn\n",
    "from    torch import optim\n",
    "from    torch.nn import functional as F\n",
    "from    torch.utils.data import TensorDataset, DataLoader\n",
    "from    torch import optim\n",
    "import  numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from   models.learner import Learner\n",
    "from models.generator import Generator\n",
    "from    copy import deepcopy\n",
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "from utils.dataloader import train_data_gen , test_data_gen\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import json\n",
    "# import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d53ff7f-c937-4105-a1f6-dfd8b919a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/gen8.json') as json_file:\n",
    "    args = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24889abc-a8cf-4ba6-b0f0-7b8e2611f95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 30000, 'n_way': 5, 'k_spt': 1, 'k_qry': 10, 'img_sz': 84, 'tasks_per_batch': 5, 'img_c': 3, 'meta_gen_lr': 0.0005, 'meta_discrim_lr': 0.0001, 'update_lr': 0.004, 'update_steps': 1, 'update_steps_test': 1, 'loss': 'cross_entropy', 'min_learning_rate': 1e-15, 'number_of_training_steps_per_iter': 4, 'multi_step_loss_num_epochs': 15, 'spy_gen_num': 5, 'qry_gen_num': 25, 'num_distractor': 0, 'batch_for_gradient': 50, 'no_save': 0, 'learn_inner_lr': 0, 'create_graph': 0, 'msl': 0, 'single_fast_test': 0, 'consine_schedule': 0, 'save_path': 'gen13'}\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5f2933-f22d-442f-8001-aedb930cafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"images/\" + args[\"save_path\"]):\n",
    "    shutil.rmtree(\"images/\" + args[\"save_path\"])\n",
    "    \n",
    "if os.path.exists(\"data/\" + args[\"save_path\"]):\n",
    "    shutil.rmtree(\"data/\" + args[\"save_path\"])\n",
    "    \n",
    "if os.path.exists(\"save_models/\" + args[\"save_path\"]):\n",
    "    shutil.rmtree(\"save_models/\" + args[\"save_path\"])\n",
    "    \n",
    "if os.path.exists(\"runs/\" + args[\"save_path\"]):\n",
    "    shutil.rmtree(\"runs/\" + args[\"save_path\"])    \n",
    "\n",
    "writer = SummaryWriter('runs/' + args[\"save_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5219417-95fd-442b-810e-3ae324fde36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    if not os.path.exists(\"images/\" + path):\n",
    "        os.makedirs(\"images/\" + path)\n",
    "        \n",
    "    if not os.path.exists(\"data/\" + path):\n",
    "        os.makedirs(\"data/\" + path)\n",
    "        \n",
    "    if not os.path.exists(\"save_models/\" + path):\n",
    "        os.makedirs(\"save_models/\" + path)        \n",
    "\n",
    "\n",
    "def save_imgs(path, imgs, step):\n",
    "\n",
    "    some_imgs = np.reshape(imgs, [imgs.shape[0]*imgs.shape[1], -1])[0:50]\n",
    "\n",
    "    # save png of imgs\n",
    "    i = 0\n",
    "    for flat_img in some_imgs:\n",
    "        img = flat_img.reshape(3,84,84).swapaxes(0,1).swapaxes(1,2)\n",
    "        im = ((img - np.min(img))*255/(np.max(img - np.min(img)))).astype(np.uint8)\n",
    "        if i < 15:\n",
    "            plt.subplot(5, 3, i+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(im)\n",
    "        i += 1\n",
    "    plt.savefig(\"images/\" + path + \"/images_step\" + str(step) + \".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c83a7d-2d03-4a4d-9590-54f2f78bf957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load datasets/BelgiumTSC\n",
      "load complete time 0.32890987396240234\n",
      "load datasets/ArTS\n",
      "load complete time 0.3370673656463623\n",
      "load datasets/chinese_traffic_sign\n",
      "load complete time 0.5610349178314209\n",
      "load datasets/CVL\n",
      "load complete time 0.39136600494384766\n",
      "load datasets/FullJCNN2013\n",
      "load complete time 0.21463298797607422\n",
      "load datasets/logo_2k\n",
      "load complete time 0.9514026641845703\n",
      "load datasets/GTSRB\n",
      "load complete time 0.08525896072387695\n",
      "load datasets/DFG\n",
      "load complete time 0.03299832344055176\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = train_data_gen(args)\n",
    "test_data_generator = test_data_gen(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94799fe8-a071-4f5e-9068-ab7abb8e7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = 64\n",
    "discriminator_config = [\n",
    "    ('conv2d', [ndf, 3, 4, 4, 2, 1]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    # ('bn', [ndf]),\n",
    "    \n",
    "    ('conv2d', [ndf*2, ndf, 4, 4, 2, 1]),\n",
    "    ('bn', [ndf*2]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "\n",
    "    ('conv2d', [ndf*4, ndf*2, 4, 4, 2, 1]),\n",
    "    ('bn', [ndf*4]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    \n",
    "    \n",
    "    ('conv2d', [ndf*8, ndf*4, 4, 4, 2, 1]),\n",
    "    ('bn', [ndf*8]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    \n",
    "    ('conv2d', [1,ndf*8 , 2, 2, 1, 0]),\n",
    "    ('flatten', []),\n",
    "    ('linear',[6, 16]),\n",
    "    ('softmax',[])\n",
    "]\n",
    "\n",
    "nz = 100\n",
    "ngf = 64\n",
    "gen_config = [\n",
    "    ('convert_z',[]),\n",
    "    ('convt2d',[nz,ngf*8,4,4,1,0]),\n",
    "    ('bn',[ngf * 8]),\n",
    "    ('leakyrelu', [.2, True]),  \n",
    "    \n",
    "    ('convt2d',[ngf*8,ngf*4,4,4,2,0]),\n",
    "    ('bn',[ngf * 4]),\n",
    "    ('leakyrelu', [.2, True]),  \n",
    "    \n",
    "    ('convt2d',[ngf*4,ngf*2,4,4,2,0]),\n",
    "    ('bn',[ngf * 2]),\n",
    "    ('leakyrelu', [.2, True]),  \n",
    "    \n",
    "    ('convt2d',[ngf*2,ngf,3,3,2,1]),\n",
    "    ('bn',[ngf]),\n",
    "    ('leakyrelu', [.2, True]),      \n",
    "    \n",
    "    ('convt2d',[ngf,3,3,3,2,1]),\n",
    "    ('convt2d',[3,3,2,2,1,1]),\n",
    "    (\"tanh\",[])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce16fb30-6933-4607-ac3c-8712f6e9b36e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Meta(nn.Module):\n",
    "    \"\"\"\n",
    "    Meta Learner with GAN incorporated\n",
    "    \"\"\"\n",
    "    def __init__(self, args, discriminator_config, gen_config):\n",
    "        \"\"\"\n",
    "        :param args:\n",
    "        \"\"\"\n",
    "        super(Meta, self).__init__()\n",
    "        \n",
    "        cuda = torch.cuda.is_available()\n",
    "        self.FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor \n",
    "        self.LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "        self.total_epochs = args[\"epoch\"]   \n",
    "        # model parameters config\n",
    "        self.meta_gen_lr = args[\"meta_gen_lr\"]\n",
    "        self.meta_discrim_lr = args[\"meta_discrim_lr\"]\n",
    "        \n",
    "        self.update_lr = args[\"update_lr\"]\n",
    "        \n",
    "        self.update_steps = args[\"update_steps\"]\n",
    "        self.update_steps_test = args[\"update_steps_test\"]\n",
    "        \n",
    "        # dataset config\n",
    "        self.img_c = args[\"img_c\"]\n",
    "        self.img_sz = args[\"img_sz\"]        \n",
    "        self.n_way = args[\"n_way\"]\n",
    "        self.k_spt = args[\"k_spt\"]\n",
    "        self.k_qry = args[\"k_qry\"]\n",
    "        self.MSL = args[\"msl\"]\n",
    "        # generator num\n",
    "        self.spy_gen_num = args[\"spy_gen_num\"]\n",
    "        self.qry_gen_num = args[\"qry_gen_num\"]\n",
    "        # query gan batch\n",
    "        self.batch_for_gradient = args[\"batch_for_gradient\"]\n",
    "        self.fix_noise = torch.randn(self.batch_for_gradient, nz,1,1, device=device)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        # load model\n",
    "        self.generator = Generator(gen_config, self.img_c, self.img_sz)\n",
    "        self.discrim_net = Learner(discriminator_config, self.img_c, self.img_sz)\n",
    "        beta1 = 0.0\n",
    "        beta2 = 0.0\n",
    "\n",
    "\n",
    "        self.meta_gen_optim = optim.Adam(self.generator.parameters(), lr=self.meta_gen_lr,betas=(beta1, 0.9))\n",
    "        self.meta_d_optim = optim.Adam(self.discrim_net.parameters(), lr=self.meta_discrim_lr,betas=(beta2, 0.9))\n",
    "\n",
    "\n",
    "        self.real_value = 1\n",
    "        self.fake_value = 0\n",
    "    \n",
    "    def pred(self, x, weights=None, nets=None, nway=True, discrim=True, conditions=False):\n",
    "        if weights == None:\n",
    "            discrim_weights = self.discrim_net.parameters()\n",
    "        else:\n",
    "            discrim_weights = weights\n",
    "\n",
    "        discrim_logits = self.discrim_net(x, vars=discrim_weights, bn_training=True) if discrim else None\n",
    "          \n",
    "        return discrim_logits\n",
    "\n",
    "    def get_num_corrects(self, y, x=None, weights=None):\n",
    "            \n",
    "        with torch.no_grad():\n",
    "\n",
    "            discrim_logits = self.pred(x, weights=weights)[:,0]\n",
    "            nway_correct = (discrim_logits).mean().item()\n",
    "\n",
    "        return nway_correct\n",
    "\n",
    "    def update_weights(self, net_losses, net_weights,learned_lrs):\n",
    "\n",
    "        update_lr = self.update_lr\n",
    "        grad = torch.autograd.grad(net_losses, net_weights)\n",
    "        weights = list(map(lambda p: p[1] - update_lr * p[0], zip(grad, net_weights)))\n",
    "\n",
    "        return weights\n",
    "    \n",
    "    def meta_test(self,qry_img,qry_label,discrim_weight,gen_weight):\n",
    "        ### discriminator train\n",
    "        q_real_discrim_logits = self.pred(qry_img, weights=discrim_weight)[:,0]\n",
    "\n",
    "        real_discrim_loss_q = self.criterion(q_real_discrim_logits, qry_label)\n",
    "\n",
    "        discrim_fake_label = torch.full((self.qry_gen_num,), self.fake_value, dtype=torch.float, device=device) \n",
    "        noise = torch.randn(self.qry_gen_num, nz,1,1, device=device)\n",
    "        q_gen = torch.empty(0,3,84,84).cuda()\n",
    "        \n",
    "        if self.qry_gen_num < self.batch_for_gradient:\n",
    "            q_gen = self.generator(qry_img, noise , vars=gen_weight)\n",
    "        else:\n",
    "            for i in range(self.qry_gen_num//self.batch_for_gradient):\n",
    "                noise_tmp = noise[i*self.batch_for_gradient:(i+1)*self.batch_for_gradient]\n",
    "                q_gen = torch.cat([q_gen,self.generator(qry_img[i*self.batch_for_gradient:(i+1)*self.batch_for_gradient], noise_tmp , vars=gen_weight)])\n",
    "\n",
    "        q_fake_discrim_logits = self.pred(q_gen.detach(), weights=discrim_weight)[:,0]\n",
    "        fake_discrim_loss_q = self.criterion(q_fake_discrim_logits, discrim_fake_label)\n",
    "        d_loss_q = (fake_discrim_loss_q + real_discrim_loss_q)\n",
    "        \n",
    "        ### generator train\n",
    "        gen_fake_label = torch.full((self.qry_gen_num,), self.real_value, dtype=torch.float, device=device)\n",
    "        gen_q_discrim = self.pred(q_gen, weights=discrim_weight)[:,0]\n",
    "        g_loss_q = self.criterion(gen_q_discrim, gen_fake_label)\n",
    "        return d_loss_q, g_loss_q\n",
    "\n",
    "    def single_task_forward(self, x_spt, y_spt, x_qry, y_qry, update_steps,nets=None, images=False):\n",
    "        \n",
    "        corrects = {key: np.zeros(update_steps + 1) for key in \n",
    "                        [\n",
    "                        \"D(x)\",\n",
    "                        \"D(G(z))\"\n",
    "                        ]}\n",
    "\n",
    "        y_spt = torch.full((y_spt.size(0),), self.real_value, dtype=torch.float, device=device)\n",
    "        y_qry = torch.full((y_qry.size(0),), self.real_value, dtype=torch.float, device=device)\n",
    "        support_sz, c_, h, w = x_spt.size()\n",
    "        nz = 100\n",
    "\n",
    "        discrim_weights,gen_weights = [x.parameters() for x in nets]\n",
    "\n",
    "        # this is the meta-test loss and accuracy before first update\n",
    "\n",
    "        q_discrim = self.get_num_corrects(y=y_qry, weights=None, x=x_qry)\n",
    "        corrects[\"D(x)\"][0] += q_discrim\n",
    "        # run the i-th task and compute loss for k-th inner update\n",
    "        \n",
    "        for k in range(1, update_steps + 1):\n",
    "            ## discrim loss\n",
    "            noise = torch.randn(self.spy_gen_num, nz , 1, 1, device=device)\n",
    "            x_gen = self.generator(x_spt, noise , vars=gen_weights)\n",
    "            \n",
    "            # update discrim weight\n",
    "\n",
    "            real_discrim_logits = self.pred(x_spt, weights=discrim_weights)[:,0]\n",
    "            # real_discrim_logits = self.pred(x_spt, weights=discrim_weights)\n",
    "\n",
    "            fake_discrim_logits = self.pred(x_gen, weights=discrim_weights)[:,0]\n",
    "            # fake_discrim_logits = self.pred(x_gen, weights=discrim_weights)\n",
    "            \n",
    "            fake_label = torch.full((self.spy_gen_num,), self.fake_value, dtype=torch.float, device=device)\n",
    "            \n",
    "\n",
    "            real_discrim_loss = self.criterion(real_discrim_logits, y_spt)\n",
    "            fake_discrim_loss = self.criterion(fake_discrim_logits,fake_label)\n",
    "            D_loss = fake_discrim_loss + real_discrim_loss\n",
    "            # print(fake_discrim_loss.item(),real_discrim_loss.item())\n",
    "            discrim_weights = self.update_weights(D_loss, discrim_weights,self.update_lr) \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                x_gen = self.generator(x_qry, self.fix_noise , vars=gen_weights) \n",
    "                gen_correct = self.pred(x_gen, weights=discrim_weights)[:,0]\n",
    "                gen_correct = gen_correct.mean().item()\n",
    "                corrects[\"D(G(z))\"][k-1] += gen_correct\n",
    "                \n",
    "                q_discrim_correct = self.get_num_corrects(y=y_qry, x=x_qry, weights=discrim_weights)\n",
    "                corrects[\"D(x)\"][k] += q_discrim_correct\n",
    "#             # meta-test nway and discrim accuracy\n",
    "#             # [query_sz]\n",
    "        \n",
    "#         # final gen-discrim and gen-nway accuracy\n",
    "        with torch.no_grad():\n",
    "            x_gen = self.generator(x_qry, self.fix_noise , vars=gen_weights)\n",
    "            gen_correct = self.pred(x_gen, weights=discrim_weights)[:,0]\n",
    "            # gen_correct = self.pred(x_gen, weights=discrim_weights)\n",
    "            gen_correct = gen_correct.mean().item()\n",
    "            corrects[\"D(G(z))\"][-1] += gen_correct\n",
    "        d_loss_q, g_loss_q = self.meta_test(x_qry,y_qry,discrim_weights,gen_weights)\n",
    "            \n",
    "        if images:\n",
    "            return d_loss_q,g_loss_q, corrects, x_gen\n",
    "        else:\n",
    "            return d_loss_q,g_loss_q, corrects\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry,step):\n",
    "        \"\"\"\n",
    "        :param x_spt:   [b, support_sz, c_, h, w]\n",
    "        :param y_spt:   [b, support_sz]\n",
    "        :param x_qry:   [b, query_sz, c_, h, w]\n",
    "        :param y_qry:   [b, query_sz]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.current_epoch = step \n",
    "        tasks_per_batch, support_sz, c_, h, w = x_spt.size()\n",
    "        query_sz = x_qry.size(1)\n",
    "        g_loss_q = 0\n",
    "        d_loss_q = 0\n",
    "        gen_losses_q = [0 for _ in range(self.update_steps + 1)]\n",
    "        discrim_losses_q = [0 for _ in range(self.update_steps + 1)]\n",
    "        corrects = {key: np.zeros(self.update_steps + 1) for key in \n",
    "                        [\n",
    "                        \"D(x)\",\n",
    "                        \"D(G(z))\"\n",
    "                        ]}\n",
    "        net = [self.discrim_net,self.generator]\n",
    "        for i in range(tasks_per_batch):\n",
    "            d_loss_q_tmp,g_loss_q_tmp, corrects_tmp = self.single_task_forward(x_spt[i], y_spt[i], x_qry[i], y_qry[i],self.update_steps,nets = net,images=False)\n",
    "            g_loss_q += g_loss_q_tmp\n",
    "            d_loss_q += d_loss_q_tmp\n",
    "            assert len(corrects_tmp.keys()) == len(corrects.keys())\n",
    "            for key in corrects.keys():\n",
    "                corrects[key] += corrects_tmp[key]\n",
    "            \n",
    "        # end of all tasks\n",
    "        # sum over final losses on query set across all tasks\n",
    "        if step > 30:\n",
    "            g_loss_q /= tasks_per_batch\n",
    "            self.meta_gen_optim.zero_grad()\n",
    "            g_loss_q.backward()\n",
    "            self.meta_gen_optim.step()        \n",
    "\n",
    "        # optimize theta parameters\n",
    "        d_loss_q /= tasks_per_batch\n",
    "        self.meta_d_optim.zero_grad()\n",
    "        d_loss_q.backward()\n",
    "        self.meta_d_optim.step()\n",
    "        \n",
    "        accs = {}\n",
    "        accs[\"D(x)\"] = corrects[\"D(x)\"] / (tasks_per_batch)\n",
    "        accs[\"D(G(z))\"] = corrects[\"D(G(z))\"] / (tasks_per_batch)\n",
    "\n",
    "        return accs,d_loss_q,g_loss_q\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x_spt:   [support_sz, c_, h, w]\n",
    "        :param y_spt:   [support_sz]\n",
    "        :param x_qry:   [query_sz, c_, h, w]\n",
    "        :param y_qry:   [query_sz]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        support_sz, c_, h, w = x_spt.size()\n",
    "\n",
    "        assert len(x_spt.shape) == 4\n",
    "\n",
    "        query_sz = x_qry.size(0)\n",
    "\n",
    "        # in order to not ruin the state of running_mean/variance and bn_weight/bias\n",
    "        # we finetunning on the copied model instead of self.net\n",
    "        \n",
    "        discrim_net = deepcopy(self.discrim_net)\n",
    "        generator = deepcopy(self.generator)\n",
    "        net = [self.discrim_net,self.generator]\n",
    "        d_loss_q,g_loss_q, corrects, imgs = self.single_task_forward(x_spt, y_spt, x_qry, y_qry,self.update_steps_test, nets=net,images=True)\n",
    "\n",
    "        del discrim_net\n",
    "        \n",
    "        accs[\"D(x)\"] = corrects[\"D(x)\"]\n",
    "        accs[\"D(G(z))\"] = corrects[\"D(G(z))\"]\n",
    "\n",
    "        return accs, imgs,d_loss_q,g_loss_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14bddb2-264f-4a65-965b-bb567e7197c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa4a0460dd544bc8a05c8bdab477d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "d loss: 2.2190911769866943\n",
      "g loss: 15.659947395324707\n",
      "accs {'D(x)': array([0.10418406, 0.39395587]), 'D(G(z))': array([0.19073502, 0.19073739])}\n",
      "d loss: 1.3657874807715416\n",
      "g loss: 2.6402281284332276\n",
      "Test acc: {'D(x)': array([0.16414322, 0.47778267]), 'D(G(z))': array([0.21154787, 0.21154806])}\n",
      "step 100\n",
      "d loss: 0.1755252331495285\n",
      "g loss: 5.865131855010986\n",
      "accs {'D(x)': array([0.94300519, 0.89143926]), 'D(G(z))': array([0.00517918, 0.00517841])}\n",
      "step 200\n",
      "d loss: 0.06769086420536041\n",
      "g loss: 9.279826164245605\n",
      "accs {'D(x)': array([0.99335139, 0.9532977 ]), 'D(G(z))': array([0.00030161, 0.00030158])}\n",
      "step 300\n",
      "d loss: 0.6241551637649536\n",
      "g loss: 1.8256752490997314\n",
      "accs {'D(x)': array([0.99720294, 0.90198896]), 'D(G(z))': array([0.32780327, 0.32779854])}\n",
      "step 400\n",
      "d loss: 0.9070612192153931\n",
      "g loss: 2.7805678844451904\n",
      "accs {'D(x)': array([0.99362781, 0.6633253 ]), 'D(G(z))': array([0.18089614, 0.18090179])}\n",
      "step 500\n",
      "d loss: 2.581021785736084\n",
      "g loss: 2.9790236949920654\n",
      "accs {'D(x)': array([0.97191193, 0.16773573]), 'D(G(z))': array([0.11574372, 0.11574366])}\n",
      "d loss: 2.247886948287487\n",
      "g loss: 0.4043468203395605\n",
      "Test acc: {'D(x)': array([0.99807447, 0.86898756]), 'D(G(z))': array([0.68058038, 0.68056411])}\n",
      "step 600\n",
      "d loss: 1.9456497430801392\n",
      "g loss: 0.357808917760849\n",
      "accs {'D(x)': array([0.9928211 , 0.82455236]), 'D(G(z))': array([0.73145422, 0.73144212])}\n",
      "step 700\n",
      "d loss: 1.2466524839401245\n",
      "g loss: 0.9705598950386047\n",
      "accs {'D(x)': array([0.98239839, 0.61212335]), 'D(G(z))': array([0.41893855, 0.41893693])}\n",
      "step 800\n",
      "d loss: 0.8766611218452454\n",
      "g loss: 2.795335531234741\n",
      "accs {'D(x)': array([0.99016485, 0.62278148]), 'D(G(z))': array([0.11589242, 0.11589208])}\n",
      "step 900\n",
      "d loss: 1.3083337545394897\n",
      "g loss: 1.6368039846420288\n",
      "accs {'D(x)': array([0.98355932, 0.59953931]), 'D(G(z))': array([0.33226278, 0.33226379])}\n",
      "step 1000\n",
      "d loss: 0.7776718735694885\n",
      "g loss: 1.3177903890609741\n",
      "accs {'D(x)': array([0.99565078, 0.74574026]), 'D(G(z))': array([0.29967654, 0.29967024])}\n",
      "d loss: 0.8784797204658389\n",
      "g loss: 1.8397590033710003\n",
      "Test acc: {'D(x)': array([0.98089123, 0.63136768]), 'D(G(z))': array([0.16942763, 0.16942374])}\n",
      "step 1100\n",
      "d loss: 0.6741941571235657\n",
      "g loss: 3.3215272426605225\n",
      "accs {'D(x)': array([0.96674337, 0.62792768]), 'D(G(z))': array([0.07791092, 0.07791118])}\n",
      "step 1200\n",
      "d loss: 0.5107898712158203\n",
      "g loss: 2.94977068901062\n",
      "accs {'D(x)': array([0.98300855, 0.75650604]), 'D(G(z))': array([0.0715212 , 0.07152028])}\n",
      "step 1300\n",
      "d loss: 0.881541907787323\n",
      "g loss: 0.9629822969436646\n",
      "accs {'D(x)': array([0.99761659, 0.89311182]), 'D(G(z))': array([0.48255111, 0.48255017])}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mamlGAN = Meta(args, discriminator_config, gen_config).to(device)\n",
    "step = 0\n",
    "path = args[\"save_path\"]\n",
    "mkdir_p(path)\n",
    "best_acc = []\n",
    "\n",
    "with tqdm.tqdm(initial=step,\n",
    "                   total=int(args[\"epoch\"])) as pbar_train:\n",
    "    for _ in range(args[\"epoch\"] * args[\"tasks_per_batch\"]//6000):\n",
    "        # fetch meta_batchsz num of episode each time\n",
    "        train_dataloader = DataLoader(train_data_generator, args[\"tasks_per_batch\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "        for _, (x_spt, y_spt, x_qry, y_qry) in enumerate(train_dataloader):\n",
    "            x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "\n",
    "            accs,d_loss,g_loss = mamlGAN(x_spt, y_spt, x_qry, y_qry,step)\n",
    "            # accs,d_loss = mamlGAN(x_spt, y_spt, x_qry, y_qry,step)\n",
    "            writer.add_scalar('Loss/train_d_loss', d_loss, step)\n",
    "            writer.add_scalar('Loss/train_g_loss', g_loss, step)\n",
    "            writer.add_scalar('Accuracy/\"train_D(x)', accs[\"D(x)\"][-1], step)\n",
    "            writer.add_scalar('Accuracy/\"train_D(G(z))', accs[\"D(G(z))\"][-1], step)\n",
    "            if step % 100 == 0:\n",
    "                print(\"step \" + str(step))\n",
    "                print('d loss:',d_loss.item())\n",
    "                print('g loss:',g_loss.item())\n",
    "                print(\"accs\",accs)\n",
    "\n",
    "\n",
    "            if step % 500 == 0:  # evaluation\n",
    "                db_test = DataLoader(test_data_generator, 1, shuffle=True, num_workers=4, pin_memory=True)\n",
    "                accs_all_test = []\n",
    "                imgs_all_test = []\n",
    "                d_loss_all_test = []\n",
    "                g_loss_all_test = []\n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "\n",
    "                    # accs, d_loss = mamlGAN.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs, imgs,d_loss,g_loss = mamlGAN.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "\n",
    "                    accs_all_test.append(accs)\n",
    "                    imgs_all_test.append(imgs.cpu().detach().numpy())\n",
    "                    d_loss_all_test.append(d_loss.item())\n",
    "                    g_loss_all_test.append(g_loss.item())\n",
    "\n",
    "                imgs_all_test = np.array(imgs_all_test)\n",
    "                # [b, update_step+1]\n",
    "                # accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                d_loss = np.mean(np.array(d_loss_all_test))\n",
    "                g_loss = np.mean(np.array(g_loss_all_test))\n",
    "\n",
    "                print('d loss:',d_loss)\n",
    "                print('g loss:',g_loss)\n",
    "                print('Test acc:', accs)    \n",
    "\n",
    "                writer.add_scalar('Loss/test_d_loss', d_loss, step)\n",
    "                writer.add_scalar('Loss/test_g_loss', g_loss, step)\n",
    "                writer.add_scalar('Accuracy/\"test_D(x)', accs[\"D(x)\"][-1], step)\n",
    "                writer.add_scalar('Accuracy/\"test_D(G(z))', accs[\"D(G(z))\"][-1], step)\n",
    "\n",
    "                if not len(best_acc):\n",
    "                    best_acc = accs\n",
    "                    best_epoch = step\n",
    "                    torch.save({'model_state_dict': mamlGAN.state_dict()}, \"save_models/\" + path + \"/best.pth\")\n",
    "                else:\n",
    "                    if max(accs) > max(best_acc):\n",
    "                        best_acc = accs\n",
    "                        best_epoch = step\n",
    "                        torch.save({'model_state_dict': mamlGAN.state_dict()}, \"save_models/\" + path + \"/best.pth\")\n",
    "                torch.save({'model_state_dict': mamlGAN.state_dict()}, \"save_models/\" + path + \"/model_step\" + str(step) + \".pth\")\n",
    "\n",
    "                save_imgs(path, imgs_all_test, step)\n",
    "\n",
    "            step = step + 1\n",
    "            pbar_train.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagan",
   "language": "python",
   "name": "metagan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
