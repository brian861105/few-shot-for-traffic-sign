{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9034beb-c9ed-4806-bef5-c1334415cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch\n",
    "from    torch import nn\n",
    "from    torch import optim\n",
    "from    torch.nn import functional as F\n",
    "from    torch.utils.data import TensorDataset, DataLoader\n",
    "from    torch import optim\n",
    "import  numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from   models.learner import Learner\n",
    "from models.generator import Generator\n",
    "from    copy import deepcopy\n",
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "from utils.dataloader import train_data_gen , test_data_gen\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import json\n",
    "# import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32658f4-5aef-4882-b21d-71bda397caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"save_models/0612_maml_gen/model_step9900.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d53ff7f-c937-4105-a1f6-dfd8b919a4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 96000, 'n_way': 5, 'k_spt': 1, 'k_qry': 15, 'img_sz': 84, 'tasks_per_batch': 5, 'img_c': 3, 'meta_gen_lr': 0.0005, 'meta_discrim_lr': 0.0001, 'update_lr': 0.004, 'update_steps': 2, 'update_steps_test': 2, 'loss': 'cross_entropy', 'min_learning_rate': 1e-15, 'number_of_training_steps_per_iter': 4, 'multi_step_loss_num_epochs': 15, 'spy_gen_num': 5, 'qry_gen_num': 25, 'num_distractor': 2, 'spy_distractor_num': 1, 'qry_distractor_num': 15, 'batch_for_gradient': 25, 'no_save': 0, 'learn_inner_lr': 0, 'create_graph': 0, 'msl': 0, 'single_fast_test': 0, 'consine_schedule': 0, 'save_path': '0625_5way1shot0distractor1gen'}\n"
     ]
    }
   ],
   "source": [
    "with open('configs/0625_5way1shot0distractor1gen.json') as json_file:\n",
    "    args = json.load(json_file)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5f2933-f22d-442f-8001-aedb930cafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(\"images/\" + args[\"save_path\"]):\n",
    "#     shutil.rmtree(\"images/\" + args[\"save_path\"])\n",
    "    \n",
    "# if os.path.exists(\"data/\" + args[\"save_path\"]):\n",
    "#     shutil.rmtree(\"data/\" + args[\"save_path\"])\n",
    "    \n",
    "# if os.path.exists(\"save_models/\" + args[\"save_path\"]):\n",
    "#     shutil.rmtree(\"save_models/\" + args[\"save_path\"])\n",
    "    \n",
    "# if os.path.exists(\"runs/\" + args[\"save_path\"]):\n",
    "#     shutil.rmtree(\"runs/\" + args[\"save_path\"])    \n",
    "\n",
    "writer = SummaryWriter('metagan_runs/' + args[\"save_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5219417-95fd-442b-810e-3ae324fde36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    if not os.path.exists(\"images/\" + path):\n",
    "        os.makedirs(\"images/\" + path)\n",
    "        \n",
    "    if not os.path.exists(\"data/\" + path):\n",
    "        os.makedirs(\"data/\" + path)\n",
    "        \n",
    "    if not os.path.exists(\"save_models/\" + path):\n",
    "        os.makedirs(\"save_models/\" + path)        \n",
    "\n",
    "def save_imgs(path, imgs, step):\n",
    "\n",
    "    some_imgs = np.reshape(imgs, [imgs.shape[0]*imgs.shape[1], -1])[0:50]\n",
    "\n",
    "    # save png of imgs\n",
    "    i = 0\n",
    "    for flat_img in some_imgs:\n",
    "        img = flat_img.reshape(3,84,84).swapaxes(0,1).swapaxes(1,2)\n",
    "        im = ((img - np.min(img))*255/(np.max(img - np.min(img)))).astype(np.uint8)\n",
    "        if i < 15:\n",
    "            plt.subplot(5, 3, i+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(im)\n",
    "        i += 1\n",
    "    plt.savefig(\"images/\" + path + \"/images_step\" + str(step) + \".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c83a7d-2d03-4a4d-9590-54f2f78bf957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load datasets/BelgiumTSC\n",
      "load complete time 0.4268476963043213\n",
      "load datasets/ArTS\n",
      "load complete time 0.4329042434692383\n",
      "load datasets/chinese_traffic_sign\n",
      "load complete time 0.7351255416870117\n",
      "load datasets/CVL\n",
      "load complete time 0.5277915000915527\n",
      "load datasets/FullJCNN2013\n",
      "load complete time 0.27721738815307617\n",
      "load datasets/logo_2k\n",
      "load complete time 1.0279045104980469\n",
      "load datasets/GTSRB\n",
      "load complete time 0.10019350051879883\n",
      "load datasets/DFG\n",
      "load complete time 0.11236929893493652\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = train_data_gen(args)\n",
    "test_data_generator = test_data_gen(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94799fe8-a071-4f5e-9068-ab7abb8e7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = 64\n",
    "discriminator_config = [\n",
    "    ('conv2d', [ndf, 3, 4, 4, 2, 1]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    # ('bn', [ndf]),\n",
    "    \n",
    "    ('conv2d', [ndf*2, ndf, 4, 4, 2, 1]),\n",
    "    ('bn', [ndf*2]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "\n",
    "    ('conv2d', [ndf*4, ndf*2, 4, 4, 2, 1]),\n",
    "    ('bn', [ndf*4]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    \n",
    "    \n",
    "    ('conv2d', [ndf*8, ndf*4, 4, 4, 2, 1]),\n",
    "    ('bn', [ndf*8]),\n",
    "    ('leakyrelu', [0.2,True]),\n",
    "    \n",
    "    ('conv2d', [1,ndf*8 , 2, 2, 1, 0]),\n",
    "    ('flatten', []),\n",
    "    ('linear',[6, 16]),\n",
    "    ('softmax',[])\n",
    "]\n",
    "nz = 100\n",
    "ngf = 64\n",
    "gen_config = [\n",
    "    ('convert_z',[]),\n",
    "    ('convt2d',[nz,ngf*8,4,4,1,0]),\n",
    "    ('bn',[ngf * 8]),\n",
    "    ('leakyrelu', [.2, True]),  \n",
    "    \n",
    "    ('convt2d',[ngf*8,ngf*4,4,4,2,0]),\n",
    "    ('bn',[ngf * 4]),\n",
    "    ('leakyrelu', [.2, True]),  \n",
    "    \n",
    "    ('convt2d',[ngf*4,ngf*2,4,4,2,0]),\n",
    "    ('bn',[ngf * 2]),\n",
    "    ('leakyrelu', [.2, True]),  \n",
    "    \n",
    "    ('convt2d',[ngf*2,ngf,3,3,2,1]),\n",
    "    ('bn',[ngf]),\n",
    "    ('leakyrelu', [.2, True]),      \n",
    "    \n",
    "    ('convt2d',[ngf,3,3,3,2,1]),\n",
    "    ('convt2d',[3,3,2,2,1,1]),\n",
    "    (\"tanh\",[])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce16fb30-6933-4607-ac3c-8712f6e9b36e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Meta(nn.Module):\n",
    "    \"\"\"\n",
    "    Meta Learner with GAN incorporated\n",
    "    \"\"\"\n",
    "    def __init__(self, args, discriminator_config, gen_config):\n",
    "        \"\"\"\n",
    "        :param args:\n",
    "        \"\"\"\n",
    "        super(Meta, self).__init__()\n",
    "        \n",
    "        cuda = torch.cuda.is_available()\n",
    "        self.FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor \n",
    "        self.LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "        self.total_epochs = args[\"epoch\"]   \n",
    "        # model parameters config\n",
    "        self.meta_gen_lr = args[\"meta_gen_lr\"]\n",
    "        self.meta_discrim_lr = args[\"meta_discrim_lr\"]\n",
    "        \n",
    "        self.update_lr = args[\"update_lr\"]\n",
    "        self.consine_schedule = args[\"consine_schedule\"]\n",
    "        self.update_steps = args[\"update_steps\"]\n",
    "        self.update_steps_test = args[\"update_steps_test\"]\n",
    "        self.distractor = args[\"num_distractor\"]\n",
    "        # dataset config\n",
    "        self.img_c = args[\"img_c\"]\n",
    "        self.img_sz = args[\"img_sz\"]        \n",
    "        self.n_way = args[\"n_way\"]\n",
    "        self.k_spt = args[\"k_spt\"]\n",
    "        self.k_qry = args[\"k_qry\"]\n",
    "        self.MSL = args[\"msl\"]\n",
    "        # generator num\n",
    "        self.spy_gen_num = args[\"spy_gen_num\"]\n",
    "        self.qry_gen_num = args[\"qry_gen_num\"]\n",
    "        # query gan batch\n",
    "        self.batch_for_gradient = args[\"batch_for_gradient\"]\n",
    "        self.fix_noise = torch.randn(self.qry_gen_num, nz,1,1, device=device)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        # load model\n",
    "        self.generator = Generator(gen_config, self.img_c, self.img_sz)\n",
    "        self.discrim_net = Learner(discriminator_config, self.img_c, self.img_sz)\n",
    "        beta1 = 0.0\n",
    "        beta2 = 0.0\n",
    "        \n",
    "        self.meta_gen_optim = optim.Adam(self.generator.parameters(), lr=self.meta_gen_lr,betas=(beta1, 0.9))\n",
    "        self.meta_d_optim = optim.Adam(self.discrim_net.parameters(), lr=self.meta_discrim_lr,betas=(beta2, 0.9))\n",
    "        if self.consine_schedule:\n",
    "            self.min_learning_rate = 1e-8\n",
    "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer=self.meta_d_optim, T_max=self.total_epochs,\n",
    "                                                                  eta_min=self.min_learning_rate)\n",
    "        self.real_value = 1\n",
    "        self.fake_value = 0\n",
    "        self.discrim_fake = 5\n",
    "    def cross_entropy(self, output,label):\n",
    "        output = torch.log(output)\n",
    "        loss = F.nll_loss(output,label)\n",
    "        return loss\n",
    "    \n",
    "    def pred(self, x, weights=None, nets=None, nway=True, discrim=True, conditions=False):\n",
    "        if weights == None:\n",
    "            discrim_weights = self.discrim_net.parameters()\n",
    "        else:\n",
    "            discrim_weights = weights\n",
    "\n",
    "        discrim_logits = self.discrim_net(x, vars=discrim_weights, bn_training=True) if discrim else None\n",
    "          \n",
    "        return discrim_logits\n",
    "\n",
    "    def get_num_corrects(self, y, x=None, weights=None, real=True):\n",
    "        with torch.no_grad():\n",
    "            discrim_logits = self.pred(x, weights=weights)\n",
    "            if real :\n",
    "                if self.distractor:\n",
    "                    nway_pred_q = discrim_logits.argmax(dim=1)\n",
    "                else:\n",
    "                    nway_pred_q = discrim_logits[:,:-1].argmax(dim=1)\n",
    "            else:\n",
    "                nway_pred_q = discrim_logits.argmax(dim=1)\n",
    "            \n",
    "            nway_correct = torch.eq(nway_pred_q, y).sum().item()\n",
    "            pred_q = discrim_logits.argmax(dim=1)\n",
    "            other = torch.tensor([5]*len(discrim_logits)).cuda()\n",
    "            other_correct = torch.eq(pred_q, other).sum().item()\n",
    "        return nway_correct, other_correct\n",
    "\n",
    "        \n",
    "    def update_weights(self, net_losses, net_weights,learned_lrs, gen=False):\n",
    "        if gen:\n",
    "            update_lr = self.gen_update_lr\n",
    "        else:\n",
    "            update_lr = self.update_lr\n",
    "        # grad = torch.autograd.grad(net_losses, net_weights, retain_graph=True, create_graph=self.create_graph)\n",
    "        grad = torch.autograd.grad(net_losses, net_weights)\n",
    "        weights = list(map(lambda p: p[1] - update_lr * p[0], zip(grad, net_weights)))\n",
    "\n",
    "        return weights\n",
    "    \n",
    "    def meta_test(self,qry_img,qry_label,discrim_weight,gen_weight):\n",
    "        ### discriminator train\n",
    "        q_real_discrim_logits = self.pred(qry_img, weights=discrim_weight)\n",
    "\n",
    "        real_discrim_loss_q = self.cross_entropy(q_real_discrim_logits, qry_label)\n",
    "        if torch.isnan(real_discrim_loss_q):\n",
    "            print(self.current_epoch)\n",
    "            print(\"real d loss error\")\n",
    "            print(q_real_discrim_logits)\n",
    "            \n",
    "        discrim_fake_label = torch.full((self.qry_gen_num,), self.discrim_fake, dtype=torch.long, device=device) \n",
    "        noise = torch.randn(self.qry_gen_num, nz,1,1, device=device)\n",
    "        q_gen = torch.empty(0,3,84,84).cuda()\n",
    "        if self.qry_gen_num < self.batch_for_gradient:\n",
    "\n",
    "            q_gen = self.generator(qry_img, noise , vars=gen_weight)\n",
    "        else:\n",
    "            for i in range(self.qry_gen_num//self.batch_for_gradient):\n",
    "\n",
    "                noise_tmp = noise[i*self.batch_for_gradient:(i+1)*self.batch_for_gradient]\n",
    "\n",
    "                q_gen = torch.cat([q_gen,self.generator(qry_img[i*self.batch_for_gradient:(i+1)*self.batch_for_gradient], noise_tmp , vars=gen_weight)])\n",
    "        q_fake_discrim_logits = self.pred(q_gen.detach(), weights=discrim_weight)\n",
    "        fake_discrim_loss_q = self.cross_entropy(q_fake_discrim_logits, discrim_fake_label)\n",
    "\n",
    "        if torch.isnan(fake_discrim_loss_q):\n",
    "            print(\"fake d loss error\")\n",
    "            print(q_fake_discrim_logits)\n",
    "        d_loss_q = (fake_discrim_loss_q + real_discrim_loss_q)\n",
    "        \n",
    "        ### generator train\n",
    "        gen_fake_label = torch.full((self.qry_gen_num,), self.fake_value, dtype=torch.float, device=device)\n",
    "        gen_q_discrim = self.pred(q_gen, weights=discrim_weight)[:,-1]\n",
    "\n",
    "        g_loss_q = self.criterion(gen_q_discrim, gen_fake_label)\n",
    "        if torch.isnan(g_loss_q):\n",
    "            print(\"g loss error\")\n",
    "            \n",
    "        return d_loss_q, g_loss_q\n",
    "\n",
    "    def single_task_forward(self, x_spt, y_spt, x_qry, y_qry, update_steps,nets=None, images=False):\n",
    "        \n",
    "        corrects = {key: np.zeros(update_steps + 1) for key in \n",
    "                        [\n",
    "                        \"query_nway\", # number of meta-test (query) images correctly discriminated\n",
    "                        \"predict_other\",\n",
    "                        \"gen_discrim\", # number of generated images correctly discriminated\n",
    "                        ]}\n",
    "\n",
    "        support_sz, c_, h, w = x_spt.size()\n",
    "        nz = 100\n",
    "        \n",
    "        discrim_weights,gen_weights = [x.parameters() for x in nets]\n",
    "\n",
    "        # this is the meta-test loss and accuracy before first update\n",
    "\n",
    "        q_discrim,other = self.get_num_corrects(y=y_qry, weights=None, x=x_qry)\n",
    "        corrects[\"query_nway\"][0] += q_discrim\n",
    "        corrects[\"predict_other\"][0] += other\n",
    "        # run the i-th task and compute loss for k-th inner update\n",
    "        query_fake_label = torch.full((self.qry_gen_num,), self.discrim_fake, dtype=torch.long, device=device)\n",
    "        for k in range(1, update_steps + 1):\n",
    "            ## discrim loss\n",
    "            noise = torch.randn(self.spy_gen_num, nz , 1, 1, device=device)\n",
    "            x_gen = self.generator(x_spt, noise , vars=gen_weights)\n",
    "            \n",
    "            # update discrim weight\n",
    "\n",
    "            real_discrim_logits = self.pred(x_spt, weights=discrim_weights)\n",
    "            if (True in torch.isnan(real_discrim_logits)):\n",
    "                print(\"inner real d loss error\")\n",
    "                print(q_discrim,other)\n",
    "                print(query_fake_label)\n",
    "                print(noise)\n",
    "                print(x_gen)\n",
    "                print(real_discrim_logits)\n",
    "            fake_discrim_logits = self.pred(x_gen, weights=discrim_weights)\n",
    "            if (True in torch.isnan(fake_discrim_logits)):\n",
    "                print(\"inner fake d loss error\")\n",
    "                print(fake_discrim_logits)\n",
    "            fake_label = torch.full((self.spy_gen_num,), self.discrim_fake, dtype=torch.long, device=device)\n",
    "            \n",
    "            real_discrim_loss = self.cross_entropy(real_discrim_logits, y_spt)\n",
    "            fake_discrim_loss = self.cross_entropy(fake_discrim_logits,fake_label)\n",
    "            D_loss = fake_discrim_loss + real_discrim_loss\n",
    "\n",
    "            discrim_weights = self.update_weights(D_loss, discrim_weights,self.update_lr) \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                x_gen = self.generator(x_qry, self.fix_noise , vars=gen_weights) \n",
    "                gen_correct,_ = self.get_num_corrects(y=query_fake_label,x=x_gen, weights=discrim_weights,real=False)\n",
    "                corrects[\"gen_discrim\"][k-1] += gen_correct\n",
    "                \n",
    "                q_discrim_correct,other = self.get_num_corrects(y=y_qry, x=x_qry, weights=discrim_weights)\n",
    "                corrects['query_nway'][k] += q_discrim_correct\n",
    "                corrects[\"predict_other\"][k] += other\n",
    "            # meta-test nway and discrim accuracy\n",
    "            # [query_sz]\n",
    "\n",
    "        # final gen-discrim and gen-nway accuracy\n",
    "        with torch.no_grad():\n",
    "            x_gen = self.generator(x_qry, self.fix_noise , vars=gen_weights)\n",
    "            gen_correct,_ = self.get_num_corrects(y=query_fake_label,x=x_gen, weights=discrim_weights,real=False)\n",
    "            corrects[\"gen_discrim\"][-1] += gen_correct\n",
    "        d_loss_q, g_loss_q = self.meta_test(x_qry,y_qry,discrim_weights,gen_weights)\n",
    "            \n",
    "        if images:\n",
    "            return d_loss_q,g_loss_q, corrects, x_gen\n",
    "        else:\n",
    "            return d_loss_q,g_loss_q, corrects\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry,step):\n",
    "        \"\"\"\n",
    "        :param x_spt:   [b, support_sz, c_, h, w]\n",
    "        :param y_spt:   [b, support_sz]\n",
    "        :param x_qry:   [b, query_sz, c_, h, w]\n",
    "        :param y_qry:   [b, query_sz]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.current_epoch = step \n",
    "        tasks_per_batch, support_sz, c_, h, w = x_spt.size()\n",
    "        query_sz = x_qry.size(1)\n",
    "        g_loss_q = 0\n",
    "        d_loss_q = 0\n",
    "        gen_losses_q = [0 for _ in range(self.update_steps + 1)]\n",
    "        discrim_losses_q = [0 for _ in range(self.update_steps + 1)]\n",
    "        corrects = {key: np.zeros(self.update_steps + 1) for key in \n",
    "                        [\n",
    "                        \"query_nway\", # number of meta-test (query) images correctly discriminated\n",
    "                        \"predict_other\",\n",
    "                        \"gen_discrim\", # number of generated images correctly discriminated\n",
    "                        ]}\n",
    "        net = [self.discrim_net,self.generator]\n",
    "        for i in range(tasks_per_batch):\n",
    "            d_loss_q_tmp,g_loss_q_tmp, corrects_tmp = self.single_task_forward(x_spt[i], y_spt[i], x_qry[i], y_qry[i],self.update_steps,nets = net,images=False)\n",
    "            g_loss_q += g_loss_q_tmp\n",
    "            d_loss_q += d_loss_q_tmp\n",
    "            assert len(corrects_tmp.keys()) == len(corrects.keys())\n",
    "            for key in corrects.keys():\n",
    "                corrects[key] += corrects_tmp[key]\n",
    "            \n",
    "        # end of all tasks\n",
    "        # sum over final losses on query set across all tasks\n",
    "        g_loss_q /= tasks_per_batch\n",
    "        self.meta_gen_optim.zero_grad()\n",
    "        g_loss_q.backward()\n",
    "        self.meta_gen_optim.step()        \n",
    "\n",
    "        # optimize theta parameters\n",
    "        d_loss_q /= tasks_per_batch\n",
    "        self.meta_d_optim.zero_grad()\n",
    "        d_loss_q.backward()\n",
    "        self.meta_d_optim.step()\n",
    "        \n",
    "        accs = {}\n",
    "        accs[\"query_nway\"] = corrects[\"query_nway\"] / (tasks_per_batch * query_sz)\n",
    "        accs[\"predict_other\"] = corrects[\"predict_other\"] / (tasks_per_batch * query_sz)\n",
    "        accs[\"gen_discrim\"] = corrects[\"gen_discrim\"] / (tasks_per_batch * self.qry_gen_num)\n",
    "        return accs,d_loss_q,g_loss_q\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x_spt:   [support_sz, c_, h, w]\n",
    "        :param y_spt:   [support_sz]\n",
    "        :param x_qry:   [query_sz, c_, h, w]\n",
    "        :param y_qry:   [query_sz]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        support_sz, c_, h, w = x_spt.size()\n",
    "\n",
    "        assert len(x_spt.shape) == 4\n",
    "\n",
    "        query_sz = x_qry.size(0)\n",
    "\n",
    "        # in order to not ruin the state of running_mean/variance and bn_weight/bias\n",
    "        # we finetunning on the copied model instead of self.net\n",
    "        \n",
    "        discrim_net = deepcopy(self.discrim_net)\n",
    "        generator = deepcopy(self.generator)\n",
    "        net = [self.discrim_net,self.generator]\n",
    "        d_loss_q,g_loss_q, corrects, imgs = self.single_task_forward(x_spt, y_spt, x_qry, y_qry,self.update_steps_test, nets=net,images=True)\n",
    "\n",
    "        del discrim_net\n",
    "        \n",
    "        accs[\"query_nway\"] = corrects[\"query_nway\"] / (query_sz)\n",
    "        accs[\"predict_other\"] = corrects[\"predict_other\"] / (query_sz)\n",
    "        accs[\"gen_discrim\"] = corrects[\"gen_discrim\"] / (self.qry_gen_num)\n",
    "\n",
    "        return accs, imgs,d_loss_q,g_loss_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70dca449-21b5-49fb-8674-7294ad89eedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['generator.vars.0', 'generator.vars.1', 'generator.vars.2', 'generator.vars.3', 'generator.vars.4', 'generator.vars.5', 'generator.vars.6', 'generator.vars.7', 'generator.vars.8', 'generator.vars.9', 'generator.vars.10', 'generator.vars.11', 'generator.vars.12', 'generator.vars.13', 'generator.vars.14', 'generator.vars.15', 'generator.vars.16', 'generator.vars.17', 'generator.vars.18', 'generator.vars.19', 'generator.vars_bn.0', 'generator.vars_bn.1', 'generator.vars_bn.2', 'generator.vars_bn.3', 'generator.vars_bn.4', 'generator.vars_bn.5', 'generator.vars_bn.6', 'generator.vars_bn.7', 'discrim_net.vars.0', 'discrim_net.vars.1', 'discrim_net.vars.2', 'discrim_net.vars.3', 'discrim_net.vars.4', 'discrim_net.vars.5', 'discrim_net.vars.6', 'discrim_net.vars.7', 'discrim_net.vars.8', 'discrim_net.vars.9', 'discrim_net.vars.10', 'discrim_net.vars.11', 'discrim_net.vars.12', 'discrim_net.vars.13', 'discrim_net.vars.14', 'discrim_net.vars.15', 'discrim_net.vars.16', 'discrim_net.vars.17', 'discrim_net.vars_bn.0', 'discrim_net.vars_bn.1', 'discrim_net.vars_bn.2', 'discrim_net.vars_bn.3', 'discrim_net.vars_bn.4', 'discrim_net.vars_bn.5'], unexpected_keys=['model_state_dict'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mamlGAN = Meta(args, discriminator_config, gen_config).to(device)\n",
    "step = 0\n",
    "path = args[\"save_path\"]\n",
    "mkdir_p(path)\n",
    "best_acc = []\n",
    "mamlGAN.load_state_dict(torch.load(PATH),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14bddb2-264f-4a65-965b-bb567e7197c4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m mamlGAN \u001b[38;5;241m=\u001b[39m \u001b[43mMeta\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_config\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mMeta.__init__\u001b[0;34m(self, args, discriminator_config, gen_config)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# query gan batch\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_for_gradient \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_for_gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfix_noise \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqry_gen_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnz\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "with tqdm.tqdm(initial=step,\n",
    "                   total=int(args[\"epoch\"])) as pbar_train:\n",
    "    for _ in range(args[\"epoch\"] * args[\"tasks_per_batch\"]//6000):\n",
    "        train_dataloader = DataLoader(train_data_generator, args[\"tasks_per_batch\"], shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "        for _, (x_spt, y_spt, x_qry, y_qry) in enumerate(train_dataloader):\n",
    "            tmp_x_spt, tmp_y_spt, tmp_x_qry, tmp_y_qry = x_spt.squeeze(0), y_spt.squeeze(0), \\\n",
    "                                         x_qry.squeeze(0), y_qry.squeeze(0)\n",
    "            x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "\n",
    "            accs,d_loss,g_loss = mamlGAN(x_spt, y_spt, x_qry, y_qry,step)\n",
    "            writer.add_scalar('Loss/train_d_loss', d_loss, step)\n",
    "            writer.add_scalar('Loss/train_g_loss', g_loss, step)\n",
    "            writer.add_scalar('Accuracy/query_nway', accs[\"query_nway\"][-1], step)\n",
    "            writer.add_scalar('Accuracy/gen_discrim', accs[\"gen_discrim\"][-1], step)\n",
    "            writer.add_scalar('Accuracy/predict_other', accs[\"predict_other\"][-1],step)\n",
    "            if step % 100 == 0:\n",
    "                print(\"step \" + str(step))\n",
    "                print('d loss:',d_loss.item())\n",
    "                print('g loss:',g_loss.item())\n",
    "                print(\"accs\",accs)\n",
    "\n",
    "\n",
    "            if step % 300 == 0:  # evaluation\n",
    "                db_test = DataLoader(test_data_generator, 1, shuffle=True, num_workers=4, pin_memory=True)\n",
    "                accs_all_test = []\n",
    "                imgs_all_test = []\n",
    "                d_loss_all_test = []\n",
    "                g_loss_all_test = []\n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    tmp_x_spt, tmp_y_spt, tmp_x_qry, tmp_y_qry = x_spt.squeeze(0), y_spt.squeeze(0), \\\n",
    "                                                 x_qry.squeeze(0), y_qry.squeeze(0)\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "                    # accs, d_loss = mamlGAN.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs, imgs,d_loss,g_loss = mamlGAN.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "\n",
    "                    accs_all_test.append(accs)\n",
    "                    imgs_all_test.append(imgs.cpu().detach().numpy())\n",
    "                    d_loss_all_test.append(d_loss.item())\n",
    "                    g_loss_all_test.append(g_loss.item())\n",
    "\n",
    "                imgs_all_test = np.array(imgs_all_test)\n",
    "                # [b, update_step+1]\n",
    "                # accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                d_loss = np.mean(np.array(d_loss_all_test))\n",
    "                g_loss = np.mean(np.array(g_loss_all_test))\n",
    "\n",
    "                print('d loss:',d_loss)\n",
    "                print('g loss:',g_loss)\n",
    "                print('Test acc:', accs)    \n",
    "\n",
    "                writer.add_scalar('Loss/test_d_loss', d_loss, step)\n",
    "                writer.add_scalar('Loss/test_g_loss', g_loss, step)\n",
    "                writer.add_scalar('Accuracy/test_query_nway', accs[\"query_nway\"][-1], step)\n",
    "                writer.add_scalar('Accuracy/test_gen_discrim', accs[\"gen_discrim\"][-1], step)\n",
    "                writer.add_scalar('Accuracy/test_predict_other', accs[\"predict_other\"][-1],step)\n",
    "                if not len(best_acc):\n",
    "                    best_acc = accs\n",
    "                    best_epoch = step\n",
    "                    torch.save({'model_state_dict': mamlGAN.state_dict()}, \"save_models/\" + path + \"/best.pth\")\n",
    "                else:\n",
    "                    if max(accs) > max(best_acc):\n",
    "                        best_acc = accs\n",
    "                        best_epoch = step\n",
    "                        torch.save({'model_state_dict': mamlGAN.state_dict()}, \"save_models/\" + path + \"/best.pth\")\n",
    "                torch.save({'model_state_dict': mamlGAN.state_dict()}, \"save_models/\" + path + \"/model_step\" + str(step) + \".pth\")\n",
    "\n",
    "                save_imgs(path, imgs_all_test, step)\n",
    "\n",
    "            step = step + 1\n",
    "            pbar_train.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495d25e-e90e-40cb-bd0f-83fbfca071f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x_spt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba2d911-b80e-4d38-a05a-a1dbc000958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_y_spt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2a244-3e93-44c2-b93c-5fe16ce8efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x_qry.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9b473-5556-4135-b002-fae4f21fc0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_y_qry.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d76bf-f852-40a0-b429-65b488234f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_y_qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf813215-4a5f-45d9-bc68-193515ed5440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagan",
   "language": "python",
   "name": "metagan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
