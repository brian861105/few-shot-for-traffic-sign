{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6120d65-2ee9-4d82-bc09-aa008fad461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyc/miniconda3/envs/metagan/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import  torch\n",
    "from    torch import nn\n",
    "from    torch import optim\n",
    "from    torch.nn import functional as F\n",
    "from    torch.utils.data import TensorDataset, DataLoader\n",
    "from    torch import optim\n",
    "from    torch.optim import lr_scheduler\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import  numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from    copy import deepcopy\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "from utils.dataloader import train_data_gen,test_data_gen\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd4be0a-1414-4ef9-b845-52ea6018dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'epoch':24000,\n",
    "        'n_way':5,\n",
    "        'k_spt':1,\n",
    "        'k_qry':15,\n",
    "        'img_sz':64,\n",
    "        \"tasks_per_batch\":4,\n",
    "        'img_c':3,\n",
    "        'task_num': 4,\n",
    "        'meta_lr':1e-3,\n",
    "        'update_lr':2e-4,\n",
    "        'update_steps':5,\n",
    "        'update_steps_test':10,\n",
    "        \"no_save\":False,\n",
    "        \"learn_inner_lr\":True,\n",
    "        'condition_discrim':False,\n",
    "        \"loss\":\"cross_entropy\",\n",
    "        \"create_graph\":False,\n",
    "        \"num_distractor\":1,\n",
    "        'save_path':'0409_conditional_result',\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7bcc516-9f07-4cc9-a54d-ac3b6d656e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def save_train_accs(path, accs):\n",
    "    file = open(path +  '/q_nway_accuracies.txt', 'ab')\n",
    "    np.savetxt(file, np.array([accs[\"q_nway\"]]))\n",
    "    file.close()\n",
    "\n",
    "    file = open(path +  '/q_discrim_accuracies.txt', 'ab')\n",
    "    np.savetxt(file, np.array([accs[\"q_discrim\"]]))\n",
    "    file.close()\n",
    "\n",
    "    file = open(path +  '/gen_discrim_accuracies.txt', 'ab')\n",
    "    np.savetxt(file, np.array([accs[\"gen_discrim\"]]))\n",
    "    file.close()\n",
    "\n",
    "def save_test_accs(path, accs):\n",
    "    file = open(path +  '/test_q_nway_accuracies.txt', 'ab')\n",
    "    np.savetxt(file, np.array([accs]))\n",
    "    file.close()\n",
    "\n",
    "def save_imgs(path, imgs, step):\n",
    "    # save raw txt files\n",
    "    img_f=open(path+\"/images_step\" + str(step) + \".txt\",'ab')\n",
    "    some_imgs = np.reshape(imgs, [imgs.shape[0]*imgs.shape[1], -1])[0:50]\n",
    "    np.savetxt(img_f,some_imgs)\n",
    "    img_f.close()\n",
    "\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "    # save png of imgs\n",
    "    i = 0\n",
    "    for flat_img in some_imgs:\n",
    "        img = flat_img.reshape(3,args[\"img_sz\"],args[\"img_sz\"]).swapaxes(0,1).swapaxes(1,2)\n",
    "        im = ((img - np.min(img))*255/(np.max(img - np.min(img)))).astype(np.uint8)\n",
    "        if i < 49:\n",
    "            plt.subplot(7, 7, 1 + i)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(im)\n",
    "        i += 1\n",
    "    plt.savefig(path+\"/images_step\" + str(step) + \".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b18403c-afce-4948-b961-d5ff857f9e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset/BelgiumTSC\n",
      "load complete time 4.5584189891815186\n",
      "load dataset/ArTS\n",
      "load complete time 4.621725797653198\n",
      "load dataset/chinese_traffic_sign\n",
      "load complete time 0.7982516288757324\n",
      "load dataset/CVL\n",
      "load complete time 0.6074516773223877\n",
      "load dataset/FullJCNN2013\n",
      "load complete time 0.3425893783569336\n",
      "load dataset/logo_2k\n",
      "load complete time 1.3441529273986816\n",
      "load dataset/GTSRB\n",
      "load complete time 0.2050189971923828\n",
      "load dataset/DFG\n",
      "load complete time 0.07396125793457031\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = train_data_gen(args)\n",
    "test_data_generator = test_data_gen(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e41ee7-7ced-4a01-9b0b-88fbfdfda0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nway_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, args[\"n_way\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2954a79f-c6aa-45fb-9834-a0d326ec452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 60, 60]             456\n",
      "         MaxPool2d-2            [-1, 6, 30, 30]               0\n",
      "            Conv2d-3           [-1, 16, 26, 26]           2,416\n",
      "         MaxPool2d-4           [-1, 16, 13, 13]               0\n",
      "            Linear-5                  [-1, 120]         324,600\n",
      "            Linear-6                   [-1, 64]           7,744\n",
      "            Linear-7                    [-1, 5]             325\n",
      "================================================================\n",
      "Total params: 335,541\n",
      "Trainable params: 335,541\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.31\n",
      "Params size (MB): 1.28\n",
      "Estimated Total Size (MB): 1.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "nway_classifier = Nway_classifier().to(device)\n",
    "summary(nway_classifier, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c82ab319-8921-487f-94d4-088d79ed62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Semi_nway_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31c6788-2b1b-496a-a272-6ae81b0a7645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 60, 60]             456\n",
      "         MaxPool2d-2            [-1, 6, 30, 30]               0\n",
      "            Conv2d-3           [-1, 16, 26, 26]           2,416\n",
      "         MaxPool2d-4           [-1, 16, 13, 13]               0\n",
      "            Linear-5                  [-1, 120]         324,600\n",
      "            Linear-6                   [-1, 64]           7,744\n",
      "            Linear-7                    [-1, 6]             390\n",
      "================================================================\n",
      "Total params: 335,606\n",
      "Trainable params: 335,606\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.31\n",
      "Params size (MB): 1.28\n",
      "Estimated Total Size (MB): 1.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "semi_nway_classifier = Semi_nway_classifier().to(device)\n",
    "summary(semi_nway_classifier, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f493a4-7bb7-4be9-af01-db1ce4753c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2da841f-0b55-4d85-a1b6-906b79ac0dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 60, 60]             456\n",
      "         MaxPool2d-2            [-1, 6, 30, 30]               0\n",
      "            Conv2d-3           [-1, 16, 26, 26]           2,416\n",
      "         MaxPool2d-4           [-1, 16, 13, 13]               0\n",
      "            Linear-5                  [-1, 120]         324,600\n",
      "            Linear-6                   [-1, 64]           7,744\n",
      "            Linear-7                    [-1, 1]              65\n",
      "================================================================\n",
      "Total params: 335,281\n",
      "Trainable params: 335,281\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.31\n",
      "Params size (MB): 1.28\n",
      "Estimated Total Size (MB): 1.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "disrim = discriminator().to(device)\n",
    "summary(disrim, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0395c56b-5d63-4082-93f8-a6302b368825",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 100\n",
    "ngf = 64\n",
    "nc = 3\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d0a216e-f8cb-4fc2-a00a-c314ee30bff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 4, 4]         819,200\n",
      "       BatchNorm2d-2            [-1, 512, 4, 4]           1,024\n",
      "              ReLU-3            [-1, 512, 4, 4]               0\n",
      "   ConvTranspose2d-4            [-1, 256, 8, 8]       2,097,152\n",
      "       BatchNorm2d-5            [-1, 256, 8, 8]             512\n",
      "              ReLU-6            [-1, 256, 8, 8]               0\n",
      "   ConvTranspose2d-7          [-1, 128, 16, 16]         524,288\n",
      "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
      "              ReLU-9          [-1, 128, 16, 16]               0\n",
      "  ConvTranspose2d-10           [-1, 64, 32, 32]         131,072\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "  ConvTranspose2d-13            [-1, 3, 64, 64]           3,072\n",
      "             Tanh-14            [-1, 3, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 3,576,704\n",
      "Trainable params: 3,576,704\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.00\n",
      "Params size (MB): 13.64\n",
      "Estimated Total Size (MB): 16.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "generator = Generator().to(device)\n",
    "summary(generator, (100,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50d81740-f239-4385-a70a-1d3603a9a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor \n",
    "IntTensor = torch.cuda.IntTensor if cuda else torch.IntTensor \n",
    "\n",
    "params = list(nway_classifier.parameters()) + list(disrim.parameters()) + list(semi_nway_classifier.parameters())\n",
    "params += list(generator.parameters())\n",
    "\n",
    "meta_optim = optim.Adam(params, lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eead054a-9932-45c7-b41f-3718648f643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x, weights=[None, None, None], nets=None):\n",
    "\n",
    "    nway_weights, discrim_weights, semi_weights = nway_classifier,disrim,semi_nway_classifier\n",
    "    nway_net, discrim_net, semi_net = nway_classifier,disrim,semi_nway_classifier\n",
    "\n",
    "    discrim_logits = discrim_net(x)\n",
    "    class_logits = nway_net(x)\n",
    "    semi_class_logits = semi_net(x)\n",
    "\n",
    "    return class_logits, discrim_logits,semi_class_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39645689-ad49-48c7-af8f-77a834c246e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_corrects(unlabel, y=None, x=None, weights=None, class_logits=None, semi_logits=None,discrim_logits=None ,conditions=None):\n",
    "    if semi_logits == None:\n",
    "        semi_logits = class_logits\n",
    "    if unlabel:\n",
    "        nway_correct = None\n",
    "    else:\n",
    "        nway_correct = torch.eq(class_logits.argmax(dim=1), y).sum().item()\n",
    "    semi_correct = torch.eq(semi_logits.argmax(dim=1), y).sum().item()\n",
    "    return nway_correct, semi_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24d8d5e6-db53-4d91-b712-ae0d25847114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e19fa-9ff9-4154-a00c-3d6c15be919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_steps = 4\n",
    "real_val = 1.0\n",
    "fake_val = 0.0\n",
    "distractor_val = float(5 + 1)\n",
    "inner_g_optim = optim.Adam(gen_weights, 2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "for step, (x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry) in enumerate(train_data_generator):\n",
    "\n",
    "    x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), \\\n",
    "    y_qry.to(device),unlbl_x_spt.to(device),unlbl_x_qry.to(device)\n",
    "    support_sz, c_, h, w = x_spt.size()\n",
    "    corrects = {key: np.zeros(update_steps + 1) for key in \n",
    "                    [\n",
    "                    \"q_nway\", # number of meta-test (query) images correctly classified\n",
    "                    \"q_n+1_nway\",\n",
    "                    \"distractor_n+1_way\",\n",
    "                    \"nway_loss\",\n",
    "                    \"n_1_way_loss\",\n",
    "                    \"gen_loss\", # number of generated images correctly discriminated\n",
    "                    \"discrim_loss\"\n",
    "                    ]}\n",
    "\n",
    "    semi_net = deepcopy(semi_nway_classifier)\n",
    "    nway_net = deepcopy(nway_classifier)\n",
    "    discrim_net = deepcopy(disrim)\n",
    "    gen_net = deepcopy(generator)                            \n",
    "    nets = (nway_net, discrim_net, semi_nway_classifier)\n",
    "    net_weights = [net.parameters() for net in nets]\n",
    "    gen_weights = gen_net.parameters()\n",
    "\n",
    "\n",
    "    real = Variable(FloatTensor(support_sz, 1).fill_(real_val), requires_grad=False)\n",
    "    fake = Variable(FloatTensor(support_sz, 1).fill_(fake_val), requires_grad=False)\n",
    "    y_distractor = Variable(FloatTensor(support_sz).fill_(distractor_val), requires_grad=False)\n",
    "    semi_disrractor = Variable(FloatTensor(15).fill_(distractor_val), requires_grad=False)\n",
    "    # qry_distractor = Variable(FloatTensor(75, 1).fill_(distractor_val), requires_grad=False)\n",
    "    # this is the meta-test loss and accuracy before first update\n",
    "    real_class_logits, real_discrim_logits,real_semi_logits = pred(x_qry, weights=net_weights)\n",
    "    q_nway, q_semi_way = get_num_corrects(unlabel=False,y=y_qry, weights=[None, None, None],class_logits=real_class_logits ,x=x_qry)\n",
    "    corrects['q_nway'][0] += q_nway\n",
    "    corrects['q_n+1_nway'][0] += q_semi_way\n",
    "    unlbl_class_logits, unlbl_discrim_logits,unlbl_semi_logits = pred(unlbl_x_qry, weights=net_weights)\n",
    "    _, distractor_semi_way = get_num_corrects(unlabel=True, y=semi_disrractor, weights=[None, None, None],semi_logits= unlbl_class_logits,x=unlbl_x_qry)\n",
    "    corrects['distractor_n+1_way'][0] += distractor_semi_way\n",
    "\n",
    "    for k in range(1, update_steps + 1):\n",
    "        noise = torch.randn(x_spt.size(0), 100, 1, 1, device=device)\n",
    "\n",
    "        x_gen = generator(noise)\n",
    "\n",
    "        # train  discriminator\n",
    "        real_class_logits, real_discrim_logits,real_semi_logits = pred(x_spt, weights=net_weights)\n",
    "        nway_loss = F.cross_entropy(real_class_logits, y_spt)\n",
    "        real_semi_loss = F.cross_entropy(real_semi_logits, y_spt)\n",
    "        real_discrim_loss = F.binary_cross_entropy_with_logits(real_discrim_logits, real)\n",
    "\n",
    "        inner_d_optim.zero_grad()\n",
    "        real_discrim_loss.backward(retain_graph=True)\n",
    "        inner_d_optim.step()\n",
    "\n",
    "#         inner_n_way_optim.zero_grad()\n",
    "#         nway_loss.backward(retain_graph=True)\n",
    "#         inner_n_way_optim.step()            \n",
    "\n",
    "#         inner_unlabel_optim.zero_grad()\n",
    "#         nway_loss.backward(retain_graph=True)\n",
    "#         inner_unlabel_optim.step()\n",
    "\n",
    "#         _, gen_discrim_logits,gen_semi_logits = pred(x_gen, weights=net_weights)\n",
    "#         gen_discrim_loss = F.binary_cross_entropy_with_logits(gen_discrim_logits, fake)\n",
    "#         semi_disrractor = Variable(IntTensor(5).fill_(distractor_val), requires_grad=False)\n",
    "\n",
    "#         semi_disrractor = semi_disrractor.type(torch.cuda.LongTensor) \n",
    "#         gen_semi_loss = F.cross_entropy(gen_semi_logits, semi_disrractor)\n",
    "\n",
    "#         inner_d_optim.zero_grad()\n",
    "#         gen_discrim_loss.backward(retain_graph=True)\n",
    "#         inner_d_optim.step()\n",
    "\n",
    "#         inner_unlabel_optim.zero_grad()\n",
    "#         gen_semi_loss.backward(retain_graph=True)\n",
    "#         inner_unlabel_optim.step()            \n",
    "\n",
    "\n",
    "#         unlabel_class_logits, unlabel_discrim_logits,unlabel_semi_logits = pred(unlbl_x_spt, weights=net_weights)\n",
    "#         unlabel_discrim_loss = F.binary_cross_entropy_with_logits(gen_discrim_logits, real)   \n",
    "#         unlabel_semi_loss = F.cross_entropy(unlabel_semi_logits, y_distractor)\n",
    "\n",
    "#         inner_d_optim.zero_grad()\n",
    "#         unlabel_discrim_loss.backward(retain_graph=True)\n",
    "#         inner_d_optim.step()\n",
    "\n",
    "#         inner_unlabel_optim.zero_grad()\n",
    "#         unlabel_semi_loss.backward(retain_graph=True)\n",
    "#         inner_unlabel_optim.step()    \n",
    "\n",
    "#         #train generator\n",
    "#         x_gen = generator(noise)\n",
    "#         _, gen_discrim_logits,gen_semi_logits = pred(x_gen, weights=net_weights)\n",
    "#         gen_discrim_loss = F.binary_cross_entropy_with_logits(gen_discrim_logits, fake)\n",
    "#         gen_loss = -1 * torch.nn.functional.logsigmoid(gen_discrim_logits).mean() #- gen_discrim_loss\n",
    "#         inner_g_optim.zero_grad()\n",
    "#         gen_loss.backward()\n",
    "#         inner_g_optim.step()  \n",
    "\n",
    "#         # meta-test nway and discrim accuracy\n",
    "#         # [query_sz]\n",
    "\n",
    "#         q_nway, q_semi_way = get_num_corrects(unlabel=False,y=y_qry, weights=[None, None, None], x=x_qry)\n",
    "\n",
    "#         corrects['q_nway'][k] += q_nway\n",
    "#         corrects['q_n+1_nway'][k] += q_semi_way\n",
    "\n",
    "#         _, distractor_semi_way = get_num_corrects(unlabel=True, y=semi_disrractor, weights=[None, None, None], x=unlbl_x_qry)\n",
    "\n",
    "#         corrects['distractor_n+1_way'][k] += distractor_semi_way\n",
    "\n",
    "#     # meta-test loss\n",
    "#     real_class_logits, real_discrim_logits,real_semi_logits = pred(x_spt, weights=net_weights)\n",
    "#     loss_q = F.cross_entropy(real_class_logits, y_spt)\n",
    "#     print(\"gen_loss:\",gen_loss)\n",
    "#     print(\"nway_loss:\",loss_q)\n",
    "    print(\"disrim_loss\",real_discrim_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f34599-83b0-452c-8208-6fa0f2c1c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, gen_discrim_logits,gen_semi_logits = pred(x_gen, weights=net_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb662625-62c7-430c-9c46-079af68cda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meta(nn.Module):\n",
    "    def __init__(self, args, config):\n",
    "        super(Meta, self).__init__()\n",
    "        self.update_lr = args[\"update_lr\"]\n",
    "        self.meta_lr = args[\"meta_lr\"]\n",
    "        self.n_way = args[\"n_way\"]\n",
    "        self.k_spt = args[\"k_spt\"]\n",
    "        self.k_qry = args[\"k_qry\"]\n",
    "        self.task_num = args[\"task_num\"]\n",
    "        self.update_step = args[\"update_step\"]\n",
    "        self.update_step_test = args[\"update_step_test\"]\n",
    "        self.learn_inner_lr = args[\"learn_inner_lr\"]\n",
    "        self.nway_net = nway_classifier\n",
    "        self.discrim_net = disrim\n",
    "        self.semi_net = semi_nway_classifier\n",
    "        self.generator_net = generator\n",
    "        \n",
    "        cuda = torch.cuda.is_available()\n",
    "        self.FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor   \n",
    "        \n",
    "        params = list(self.nway_classifier.parameters()) + list(self.disrim.parameters()) + list(self.semi_net.parameters())\n",
    "        params += list(self.generator.parameters())\n",
    "                    \n",
    "        self.create_graph = args.create_graph\n",
    "        self.meta_optim = optim.Adam(params, lr=self.meta_lr)\n",
    "        self.loss = args.loss\n",
    "        \n",
    "        self.real_val = 1.0 # requires that real_val > fake_val\n",
    "        self.fake_val = 0.0\n",
    "        self.distractor_val = float(self.n_way + 1) # requires that real_val > fake_val\n",
    "\n",
    "    def pred(self, x, weights=[None, None, None], nets=None, nway=True, discrim=True, conditions=None):\n",
    "\n",
    "        nway_weights, discrim_weights, semi_weights = weights\n",
    "        nway_net, discrim_net, semi_net = nets\n",
    "\n",
    "        discrim_logits = discrim_net(x, conditions=conditions, vars=discrim_weights, bn_training=True) if discrim else None\n",
    "        class_logits = nway_net(x, vars=nway_weights, bn_training=True) if nway else None\n",
    "        semi_class_logits = semi_net(x, vars=semi_weights, bn_training=True) if semi_weights else None\n",
    "        \n",
    "        discrim_logits = discrim_net(x, vars=discrim_weights) if discrim else None\n",
    "        class_logits = nway_net(x, vars=nway_weights) if nway else None\n",
    "        semi_class_logits = nway_net(x,vars=nway_weights) if semi_weights else None\n",
    "\n",
    "        return class_logits, discrim_logits,semi_class_logits\n",
    "\n",
    "    def get_num_corrects(self, unlabel, y, x=None, weights=None, class_logits=None, discrim_logits=None, conditions=None):\n",
    "        with torch.no_grad():\n",
    "            if type(class_logits) == type(None):\n",
    "                \n",
    "                class_logits, discrim_logits,semi_logits = self.pred(x, weights=weights)\n",
    "            \n",
    "            nway_correct = torch.eq(class_logits.argmax(dim=1), y).sum().item()\n",
    "            semi_correct = torch.eq(semi_logits.argmax(dim=1, y).sum().item()\n",
    "                \n",
    "        return nway_correct, semi_correct\n",
    "    def loss_cross_entropy(self, class_logits, y_class, discrim_logits=None, y_discrim=None, distractor):\n",
    "\n",
    "        nway_loss = F.cross_entropy(class_logits, y_class)\n",
    "        if type(discrim_logits) == type(None):\n",
    "            return nway_loss\n",
    "        \n",
    "        discrim_loss = F.binary_cross_entropy_with_logits(discrim_logits, y_discrim)\n",
    "\n",
    "        return nway_loss, discrim_loss  \n",
    "\n",
    "    def single_task_forward(self, x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry, nets=None,generator_net = None, images=False):\n",
    "        \n",
    "        corrects = {key: np.zeros(self.update_steps + 1) for key in \n",
    "                        [\n",
    "                        \"q_nway\", # number of meta-test (query) images correctly classified\n",
    "                        \"q_n+1_nway\",\n",
    "                        \"distractor_n+1_way\",\n",
    "                        \"nway_loss\",\n",
    "                        \"n_1_way_loss\",\n",
    "                        \"gen_loss\", # number of generated images correctly discriminated\n",
    "                        \"discrim_loss\"\n",
    "                        ]}\n",
    "        \n",
    "        semi_net = deepcopy(self.semi_net)\n",
    "        nway_net = deepcopy(self.nway_net)\n",
    "        discrim_net = deepcopy(self.discrim_net)\n",
    "        gen_net = deepcopy(self.generator_net)                            \n",
    "        nets = (shared_net, nway_net, discrim_net)\n",
    "        net_weights = [net.parameters() for net in nets]\n",
    "        gen_weights = gen_net.parameters()\n",
    "                          \n",
    "        inner_g_optim = optim.Adam(gen_weights, 2e-4, betas=(0.5, 0.999))\n",
    "        inner_n_way_optim = optim.Adam(net_weights[0], 2e-4, betas=(0.5, 0.999))\n",
    "        inner_d_optim = optim.Adam(net_weights[1], 2e-4, betas=(0.5, 0.999))\n",
    "        inner_unlabel_optim = optim.Adam(net_weights[2], 2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "        # this is the meta-test loss and accuracy before first update\n",
    "        q_nway, q_semi_way = self.get_num_corrects(real=True, y=y_qry, weights=[None, None, None], x=x_qry)\n",
    "        corrects['q_nway'][0] += q_nway\n",
    "        corrects['q_n+1_nway'][0] += q_semi_way\n",
    "        y_distractor = Variable(self.FloatTensor(support_sz, 1).fill_(self.distractor_val), requires_grad=False)\n",
    "        _, distractor_semi_way = self.get_num_corrects(real=True, y=y_distractor, weights=[None, None, None], x=unlbl_x_qry)\n",
    "        corrects['distractor_n'][0] += distractor_semi_way\n",
    "\n",
    "        real = Variable(self.FloatTensor(support_sz, 1).fill_(self.real_val), requires_grad=False)\n",
    "        fake = Variable(self.FloatTensor(support_sz, 1).fill_(self.fake_val), requires_grad=False)\n",
    "\n",
    "        for k in range(1, self.update_steps + 1):\n",
    "            noise = torch.randn(x_spt.size(0), 100, 1, 1, device=device)\n",
    "            x_gen = generator(noise,vars=gen_weights) \n",
    "\n",
    "            y_spt_idxs = [int((y_spt == i).nonzero()[0]) for i in y_spt]\n",
    "\n",
    "            real_class_logits, real_discrim_logits,real_semi_logits = self.pred(x_spt, weights=net_weights)\n",
    "            gen_class_logits, gen_discrim_logits,gen_semi_logits = self.pred(x_gen, weights=net_weights)\n",
    "            gen_class_logits, gen_discrim_logits,gen_semi_logits = self.pred(unlbl_x_spt, weights=net_weights)\n",
    "                                    \n",
    "            real_nway_loss, real_discrim_loss = self.loss_cross_entropy(real_class_logits, y_spt, real_discrim_logits, real, distractor=False)\n",
    "            gen_nway_loss, gen_discrim_loss = self.loss_cross_entropy(gen_class_logits, y_gen, gen_discrim_logits, fake, distractor=True)\n",
    "            gen_nway_loss, gen_discrim_loss = self.loss_cross_entropy(gen_class_logits, y_gen, gen_discrim_logits, fake, distractor=True)\n",
    "\n",
    "            nway_loss = (gen_nway_loss + real_nway_loss) / 2\n",
    "            discrim_loss = (gen_discrim_loss + real_discrim_loss) / 2\n",
    "            shared_loss = nway_loss + discrim_loss  #\n",
    "\n",
    "            gen_loss = -1 * torch.nn.functional.logsigmoid(gen_discrim_logits).mean() #- gen_discrim_loss\n",
    "\n",
    "            net_losses = (shared_loss, nway_loss, discrim_loss)\n",
    "            if self.learn_inner_lr:\n",
    "                net_weights, gen_weights = self.update_weights_learned_lr(net_losses, net_weights, gen_loss, gen_weights, self.learned_lrs[k-1])\n",
    "            else:\n",
    "                net_weights, gen_weights = self.update_weights(net_losses, net_weights, gen_loss, gen_weights)\n",
    "\n",
    "            _, gen_discrim_correct = self.get_num_corrects(real=False, y=y_gen, class_logits=gen_class_logits, discrim_logits=gen_discrim_logits, conditions=class_image_embeddings)\n",
    "\n",
    "            corrects[\"gen_nway\"][k-1] += gen_nway_correct\n",
    "            corrects[\"gen_discrim\"][k-1] += gen_discrim_correct\n",
    "\n",
    "            # meta-test nway and discrim accuracy\n",
    "            # [query_sz]\n",
    "            q_nway_correct, q_discrim_correct = self.get_num_corrects(real=True, y=y_qry, x=x_qry, weights=net_weights, conditions=class_image_embeddings)\n",
    "            corrects['q_nway'][k] += q_nway_correct\n",
    "            corrects['q_discrim'][k] += q_discrim_correct\n",
    "\n",
    "\n",
    "        # final gen-discrim and gen-nway accuracy\n",
    "        with torch.no_grad():\n",
    "            x_gen, y_gen = self.generator(x_spt, y_spt, vars=gen_weights, bn_training=False)\n",
    "            gen_nway_correct, gen_discrim_correct = self.get_num_corrects(real=False, y=y_gen, x=x_gen, weights=net_weights, conditions=class_image_embeddings)\n",
    "\n",
    "            corrects['gen_nway'][-1] += gen_nway_correct\n",
    "            corrects['gen_discrim'][-1] += gen_discrim_correct\n",
    "\n",
    "        # meta-test loss\n",
    "        q_class_logits, _ = self.pred(x_qry, weights=net_weights, discrim=False)\n",
    "        loss_q = self.loss_cross_entropy(q_class_logits, y_qry) # doesn't use discrim loss\n",
    "\n",
    "        if images:\n",
    "            return loss_q, corrects, x_gen\n",
    "        else:\n",
    "            return loss_q, corrects\n",
    "#     def forward(self, x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry):\n",
    "\n",
    "#         task_num, setsz, c_, h, w = x_spt.size()\n",
    "#         querysz = x_qry.size(1)\n",
    "\n",
    "#         losses_q = [0 for _ in range(self.update_step + 1)]  # losses_q[i] is the loss on step i\n",
    "#         corrects = [0 for _ in range(self.update_step + 1)]\n",
    "\n",
    "#         for i in range(task_num):\n",
    "\n",
    "#             # 1. run the i-th task and compute loss for k=0\n",
    "#             logits = self.net(x_spt[i], vars=None, bn_training=True)\n",
    "#             loss = F.cross_entropy(logits, y_spt[i])\n",
    "#             grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "#             fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, self.net.parameters())))\n",
    "\n",
    "#             # this is the loss and accuracy before first update\n",
    "#             with torch.no_grad():\n",
    "#                 # [setsz, nway]\n",
    "#                 logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)\n",
    "#                 loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "#                 losses_q[0] += loss_q\n",
    "\n",
    "#                 pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "#                 correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "#                 corrects[0] = corrects[0] + correct\n",
    "\n",
    "#             # this is the loss and accuracy after the first update\n",
    "#             with torch.no_grad():\n",
    "#                 # [setsz, nway]\n",
    "#                 logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "#                 loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "#                 losses_q[1] += loss_q\n",
    "#                 # [setsz]\n",
    "#                 pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "#                 correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "#                 corrects[1] = corrects[1] + correct\n",
    "\n",
    "#             for k in range(1, self.update_step):\n",
    "#                 # 1. run the i-th task and compute loss for k=1~K-1\n",
    "#                 logits = self.net(x_spt[i], fast_weights, bn_training=True)\n",
    "#                 loss = F.cross_entropy(logits, y_spt[i])\n",
    "#                 # 2. compute grad on theta_pi\n",
    "#                 grad = torch.autograd.grad(loss, fast_weights)\n",
    "#                 # 3. theta_pi = theta_pi - train_lr * grad\n",
    "#                 fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n",
    "\n",
    "#                 logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "#                 # loss_q will be overwritten and just keep the loss_q on last update step.\n",
    "#                 loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "#                 losses_q[k + 1] += loss_q\n",
    "\n",
    "#                 with torch.no_grad():\n",
    "#                     pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "#                     correct = torch.eq(pred_q, y_qry[i]).sum().item()  # convert to numpy\n",
    "#                     corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "#         # optimize theta parameters\n",
    "#         loss_q = losses_q[-1] / task_num\n",
    "#         self.meta_optim.zero_grad()\n",
    "#         loss_q.backward()\n",
    "#         self.meta_optim.step()\n",
    "\n",
    "\n",
    "#         accs = np.array(corrects) / (querysz * task_num)\n",
    "\n",
    "#         return accs\n",
    "\n",
    "\n",
    "#     def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "#         \"\"\"\n",
    "\n",
    "#         :param x_spt:   [setsz, c_, h, w]\n",
    "#         :param y_spt:   [setsz]\n",
    "#         :param x_qry:   [querysz, c_, h, w]\n",
    "#         :param y_qry:   [querysz]\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         assert len(x_spt.shape) == 4\n",
    "\n",
    "#         querysz = x_qry.size(0)\n",
    "\n",
    "#         corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "\n",
    "#         # in order to not ruin the state of running_mean/variance and bn_weight/bias\n",
    "#         # we finetunning on the copied model instead of self.net\n",
    "#         net = deepcopy(self.net)\n",
    "\n",
    "#         # 1. run the i-th task and compute loss for k=0\n",
    "#         logits = net(x_spt)\n",
    "#         loss = F.cross_entropy(logits, y_spt)\n",
    "#         grad = torch.autograd.grad(loss, net.parameters())\n",
    "#         fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters())))\n",
    "\n",
    "#         # this is the loss and accuracy before first update\n",
    "#         with torch.no_grad():\n",
    "#             # [setsz, nway]\n",
    "#             logits_q = net(x_qry, net.parameters(), bn_training=True)\n",
    "#             # [setsz]\n",
    "#             pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "#             # scalar\n",
    "#             correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "#             corrects[0] = corrects[0] + correct\n",
    "\n",
    "#         # this is the loss and accuracy after the first update\n",
    "#         with torch.no_grad():\n",
    "#             # [setsz, nway]\n",
    "#             logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "#             # [setsz]\n",
    "#             pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "#             # scalar\n",
    "#             correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "#             corrects[1] = corrects[1] + correct\n",
    "\n",
    "#         for k in range(1, self.update_step_test):\n",
    "#             # 1. run the i-th task and compute loss for k=1~K-1\n",
    "#             logits = net(x_spt, fast_weights, bn_training=True)\n",
    "#             loss = F.cross_entropy(logits, y_spt)\n",
    "#             # 2. compute grad on theta_pi\n",
    "#             grad = torch.autograd.grad(loss, fast_weights)\n",
    "#             # 3. theta_pi = theta_pi - train_lr * grad\n",
    "#             fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n",
    "\n",
    "#             logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "#             # loss_q will be overwritten and just keep the loss_q on last update step.\n",
    "#             loss_q = F.cross_entropy(logits_q, y_qry)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "#                 correct = torch.eq(pred_q, y_qry).sum().item()  # convert to numpy\n",
    "#                 corrects[k + 1] = corrects[k + 1] + correct\n",
    "                \n",
    "#         del net\n",
    "\n",
    "#         accs = np.array(corrects) / querysz\n",
    "\n",
    "#         return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744a202-6001-4478-8697-3fb0de3ba0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mamlGAN = MetaGAN(args, shared_config, nway_config, discriminator_config, gen_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f69f6-485c-4e03-b0db-9651c0c260a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = filter(lambda x: x.requires_grad, mamlGAN.parameters())\n",
    "# num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "# print(mamlGAN)\n",
    "# print('Total trainable tensors:', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d14687-a96d-476c-8fb0-c9b638c9f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.epoch//10000):\n",
    "    # fetch meta_batchsz num of episode each time\n",
    "    db = DataLoader(mini, args.tasks_per_batch, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "    for step, (x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry) in enumerate(db):\n",
    "\n",
    "        x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "        accs = mamlGAN(x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry)\n",
    "\n",
    "        if step % 30 == 0:\n",
    "            print(\"step \" + str(step))\n",
    "            for key in accs.keys():\n",
    "                print(key + \": \" + str(accs[key]))\n",
    "            if save_model:\n",
    "                save_accs(path, accs)\n",
    "\n",
    "        if step % 500 == 0:  # evaluation\n",
    "            db_test = DataLoader(mini_test, 1, shuffle=True, num_workers=1, pin_memory=True)\n",
    "            accs_all_test = []\n",
    "            imgs_all_test = []\n",
    "            for x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry in db_test:\n",
    "                x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                             x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "\n",
    "                accs, imgs = mamlGAN.finetunning(x_spt, y_spt, x_qry, y_qry,unlbl_x_spt,unlbl_x_qry)\n",
    "                accs_all_test.append(accs)\n",
    "                imgs_all_test.append(imgs.cpu().detach().numpy())\n",
    "\n",
    "            imgs_all_test = np.array(imgs_all_test)\n",
    "\n",
    "            if save_model:\n",
    "                save_imgs(path, imgs_all_test, step)\n",
    "\n",
    "            print('Test acc:', accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagan",
   "language": "python",
   "name": "metagan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
